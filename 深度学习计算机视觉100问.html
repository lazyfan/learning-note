<!doctype html>
<html>
<head>
<meta charset='UTF-8'><meta name='viewport' content='width=device-width initial-scale=1'>
<title>深度学习计算机视觉100问</title><link href='https://fonts.loli.net/css?family=Open+Sans:400italic,700italic,700,400&subset=latin,latin-ext' rel='stylesheet' type='text/css' /><style type='text/css'>html {overflow-x: initial !important;}:root { --bg-color:#ffffff; --text-color:#333333; --select-text-bg-color:#B5D6FC; --select-text-font-color:auto; --monospace:"Lucida Console",Consolas,"Courier",monospace; }
html { font-size: 14px; background-color: var(--bg-color); color: var(--text-color); font-family: "Helvetica Neue", Helvetica, Arial, sans-serif; -webkit-font-smoothing: antialiased; }
body { margin: 0px; padding: 0px; height: auto; bottom: 0px; top: 0px; left: 0px; right: 0px; font-size: 1rem; line-height: 1.42857; overflow-x: hidden; background: inherit; tab-size: 4; }
iframe { margin: auto; }
a.url { word-break: break-all; }
a:active, a:hover { outline: 0px; }
.in-text-selection, ::selection { text-shadow: none; background: var(--select-text-bg-color); color: var(--select-text-font-color); }
#write { margin: 0px auto; height: auto; width: inherit; word-break: normal; overflow-wrap: break-word; position: relative; white-space: normal; overflow-x: visible; padding-top: 40px; }
#write.first-line-indent p { text-indent: 2em; }
#write.first-line-indent li p, #write.first-line-indent p * { text-indent: 0px; }
#write.first-line-indent li { margin-left: 2em; }
.for-image #write { padding-left: 8px; padding-right: 8px; }
body.typora-export { padding-left: 30px; padding-right: 30px; }
.typora-export .footnote-line, .typora-export li, .typora-export p { white-space: pre-wrap; }
@media screen and (max-width: 500px) {
  body.typora-export { padding-left: 0px; padding-right: 0px; }
  #write { padding-left: 20px; padding-right: 20px; }
  .CodeMirror-sizer { margin-left: 0px !important; }
  .CodeMirror-gutters { display: none !important; }
}
#write li > figure:last-child { margin-bottom: 0.5rem; }
#write ol, #write ul { position: relative; }
img { max-width: 100%; vertical-align: middle; }
button, input, select, textarea { color: inherit; font: inherit; }
input[type="checkbox"], input[type="radio"] { line-height: normal; padding: 0px; }
*, ::after, ::before { box-sizing: border-box; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p, #write pre { width: inherit; }
#write h1, #write h2, #write h3, #write h4, #write h5, #write h6, #write p { position: relative; }
p { line-height: inherit; }
h1, h2, h3, h4, h5, h6 { break-after: avoid-page; break-inside: avoid; orphans: 2; }
p { orphans: 4; }
h1 { font-size: 2rem; }
h2 { font-size: 1.8rem; }
h3 { font-size: 1.6rem; }
h4 { font-size: 1.4rem; }
h5 { font-size: 1.2rem; }
h6 { font-size: 1rem; }
.md-math-block, .md-rawblock, h1, h2, h3, h4, h5, h6, p { margin-top: 1rem; margin-bottom: 1rem; }
.hidden { display: none; }
.md-blockmeta { color: rgb(204, 204, 204); font-weight: 700; font-style: italic; }
a { cursor: pointer; }
sup.md-footnote { padding: 2px 4px; background-color: rgba(238, 238, 238, 0.7); color: rgb(85, 85, 85); border-radius: 4px; cursor: pointer; }
sup.md-footnote a, sup.md-footnote a:hover { color: inherit; text-transform: inherit; text-decoration: inherit; }
#write input[type="checkbox"] { cursor: pointer; width: inherit; height: inherit; }
figure { overflow-x: auto; margin: 1.2em 0px; max-width: calc(100% + 16px); padding: 0px; }
figure > table { margin: 0px !important; }
tr { break-inside: avoid; break-after: auto; }
thead { display: table-header-group; }
table { border-collapse: collapse; border-spacing: 0px; width: 100%; overflow: auto; break-inside: auto; text-align: left; }
table.md-table td { min-width: 32px; }
.CodeMirror-gutters { border-right: 0px; background-color: inherit; }
.CodeMirror-linenumber { user-select: none; }
.CodeMirror { text-align: left; }
.CodeMirror-placeholder { opacity: 0.3; }
.CodeMirror pre { padding: 0px 4px; }
.CodeMirror-lines { padding: 0px; }
div.hr:focus { cursor: none; }
#write pre { white-space: pre-wrap; }
#write.fences-no-line-wrapping pre { white-space: pre; }
#write pre.ty-contain-cm { white-space: normal; }
.CodeMirror-gutters { margin-right: 4px; }
.md-fences { font-size: 0.9rem; display: block; break-inside: avoid; text-align: left; overflow: visible; white-space: pre; background: inherit; position: relative !important; }
.md-diagram-panel { width: 100%; margin-top: 10px; text-align: center; padding-top: 0px; padding-bottom: 8px; overflow-x: auto; }
#write .md-fences.mock-cm { white-space: pre-wrap; }
.md-fences.md-fences-with-lineno { padding-left: 0px; }
#write.fences-no-line-wrapping .md-fences.mock-cm { white-space: pre; overflow-x: auto; }
.md-fences.mock-cm.md-fences-with-lineno { padding-left: 8px; }
.CodeMirror-line, twitterwidget { break-inside: avoid; }
.footnotes { opacity: 0.8; font-size: 0.9rem; margin-top: 1em; margin-bottom: 1em; }
.footnotes + .footnotes { margin-top: 0px; }
.md-reset { margin: 0px; padding: 0px; border: 0px; outline: 0px; vertical-align: top; background: 0px 0px; text-decoration: none; text-shadow: none; float: none; position: static; width: auto; height: auto; white-space: nowrap; cursor: inherit; -webkit-tap-highlight-color: transparent; line-height: normal; font-weight: 400; text-align: left; box-sizing: content-box; direction: ltr; }
li div { padding-top: 0px; }
blockquote { margin: 1rem 0px; }
li .mathjax-block, li p { margin: 0.5rem 0px; }
li { margin: 0px; position: relative; }
blockquote > :last-child { margin-bottom: 0px; }
blockquote > :first-child, li > :first-child { margin-top: 0px; }
.footnotes-area { color: rgb(136, 136, 136); margin-top: 0.714rem; padding-bottom: 0.143rem; white-space: normal; }
#write .footnote-line { white-space: pre-wrap; }
@media print {
  body, html { border: 1px solid transparent; height: 99%; break-after: avoid; break-before: avoid; }
  #write { margin-top: 0px; padding-top: 0px; border-color: transparent !important; }
  .typora-export * { -webkit-print-color-adjust: exact; }
  html.blink-to-pdf { font-size: 13px; }
  .typora-export #write { padding-left: 32px; padding-right: 32px; padding-bottom: 0px; break-after: avoid; }
  .typora-export #write::after { height: 0px; }
}
.footnote-line { margin-top: 0.714em; font-size: 0.7em; }
a img, img a { cursor: pointer; }
pre.md-meta-block { font-size: 0.8rem; min-height: 0.8rem; white-space: pre-wrap; background: rgb(204, 204, 204); display: block; overflow-x: hidden; }
p > .md-image:only-child:not(.md-img-error) img, p > img:only-child { display: block; margin: auto; }
p > .md-image:only-child { display: inline-block; width: 100%; }
#write .MathJax_Display { margin: 0.8em 0px 0px; }
.md-math-block { width: 100%; }
.md-math-block:not(:empty)::after { display: none; }
[contenteditable="true"]:active, [contenteditable="true"]:focus { outline: 0px; box-shadow: none; }
.md-task-list-item { position: relative; list-style-type: none; }
.task-list-item.md-task-list-item { padding-left: 0px; }
.md-task-list-item > input { position: absolute; top: 0px; left: 0px; margin-left: -1.2em; margin-top: calc(1em - 10px); border: none; }
.math { font-size: 1rem; }
.md-toc { min-height: 3.58rem; position: relative; font-size: 0.9rem; border-radius: 10px; }
.md-toc-content { position: relative; margin-left: 0px; }
.md-toc-content::after, .md-toc::after { display: none; }
.md-toc-item { display: block; color: rgb(65, 131, 196); }
.md-toc-item a { text-decoration: none; }
.md-toc-inner:hover { text-decoration: underline; }
.md-toc-inner { display: inline-block; cursor: pointer; }
.md-toc-h1 .md-toc-inner { margin-left: 0px; font-weight: 700; }
.md-toc-h2 .md-toc-inner { margin-left: 2em; }
.md-toc-h3 .md-toc-inner { margin-left: 4em; }
.md-toc-h4 .md-toc-inner { margin-left: 6em; }
.md-toc-h5 .md-toc-inner { margin-left: 8em; }
.md-toc-h6 .md-toc-inner { margin-left: 10em; }
@media screen and (max-width: 48em) {
  .md-toc-h3 .md-toc-inner { margin-left: 3.5em; }
  .md-toc-h4 .md-toc-inner { margin-left: 5em; }
  .md-toc-h5 .md-toc-inner { margin-left: 6.5em; }
  .md-toc-h6 .md-toc-inner { margin-left: 8em; }
}
a.md-toc-inner { font-size: inherit; font-style: inherit; font-weight: inherit; line-height: inherit; }
.footnote-line a:not(.reversefootnote) { color: inherit; }
.md-attr { display: none; }
.md-fn-count::after { content: "."; }
code, pre, samp, tt { font-family: var(--monospace); }
kbd { margin: 0px 0.1em; padding: 0.1em 0.6em; font-size: 0.8em; color: rgb(36, 39, 41); background: rgb(255, 255, 255); border: 1px solid rgb(173, 179, 185); border-radius: 3px; box-shadow: rgba(12, 13, 14, 0.2) 0px 1px 0px, rgb(255, 255, 255) 0px 0px 0px 2px inset; white-space: nowrap; vertical-align: middle; }
.md-comment { color: rgb(162, 127, 3); opacity: 0.8; font-family: var(--monospace); }
code { text-align: left; vertical-align: initial; }
a.md-print-anchor { white-space: pre !important; border-width: initial !important; border-style: none !important; border-color: initial !important; display: inline-block !important; position: absolute !important; width: 1px !important; right: 0px !important; outline: 0px !important; background: 0px 0px !important; text-decoration: initial !important; text-shadow: initial !important; }
.md-inline-math .MathJax_SVG .noError { display: none !important; }
.html-for-mac .inline-math-svg .MathJax_SVG { vertical-align: 0.2px; }
.md-math-block .MathJax_SVG_Display { text-align: center; margin: 0px; position: relative; text-indent: 0px; max-width: none; max-height: none; min-height: 0px; min-width: 100%; width: auto; overflow-y: hidden; display: block !important; }
.MathJax_SVG_Display, .md-inline-math .MathJax_SVG_Display { width: auto; margin: inherit; display: inline-block !important; }
.MathJax_SVG .MJX-monospace { font-family: var(--monospace); }
.MathJax_SVG .MJX-sans-serif { font-family: sans-serif; }
.MathJax_SVG { display: inline; font-style: normal; font-weight: 400; line-height: normal; zoom: 90%; text-indent: 0px; text-align: left; text-transform: none; letter-spacing: normal; word-spacing: normal; overflow-wrap: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0px; min-height: 0px; border: 0px; padding: 0px; margin: 0px; }
.MathJax_SVG * { transition: none 0s ease 0s; }
.MathJax_SVG_Display svg { vertical-align: middle !important; margin-bottom: 0px !important; margin-top: 0px !important; }
.os-windows.monocolor-emoji .md-emoji { font-family: "Segoe UI Symbol", sans-serif; }
.md-diagram-panel > svg { max-width: 100%; }
[lang="mermaid"] svg, [lang="flow"] svg { max-width: 100%; height: auto; }
[lang="mermaid"] .node text { font-size: 1rem; }
table tr th { border-bottom: 0px; }
video { max-width: 100%; display: block; margin: 0px auto; }
iframe { max-width: 100%; width: 100%; border: none; }
.highlight td, .highlight tr { border: 0px; }
svg[id^="mermaidChart"] { line-height: 1em; }


.CodeMirror { height: auto; }
.CodeMirror.cm-s-inner { background: inherit; }
.CodeMirror-scroll { overflow: auto hidden; z-index: 3; }
.CodeMirror-gutter-filler, .CodeMirror-scrollbar-filler { background-color: rgb(255, 255, 255); }
.CodeMirror-gutters { border-right: 1px solid rgb(221, 221, 221); background: inherit; white-space: nowrap; }
.CodeMirror-linenumber { padding: 0px 3px 0px 5px; text-align: right; color: rgb(153, 153, 153); }
.cm-s-inner .cm-keyword { color: rgb(119, 0, 136); }
.cm-s-inner .cm-atom, .cm-s-inner.cm-atom { color: rgb(34, 17, 153); }
.cm-s-inner .cm-number { color: rgb(17, 102, 68); }
.cm-s-inner .cm-def { color: rgb(0, 0, 255); }
.cm-s-inner .cm-variable { color: rgb(0, 0, 0); }
.cm-s-inner .cm-variable-2 { color: rgb(0, 85, 170); }
.cm-s-inner .cm-variable-3 { color: rgb(0, 136, 85); }
.cm-s-inner .cm-string { color: rgb(170, 17, 17); }
.cm-s-inner .cm-property { color: rgb(0, 0, 0); }
.cm-s-inner .cm-operator { color: rgb(152, 26, 26); }
.cm-s-inner .cm-comment, .cm-s-inner.cm-comment { color: rgb(170, 85, 0); }
.cm-s-inner .cm-string-2 { color: rgb(255, 85, 0); }
.cm-s-inner .cm-meta { color: rgb(85, 85, 85); }
.cm-s-inner .cm-qualifier { color: rgb(85, 85, 85); }
.cm-s-inner .cm-builtin { color: rgb(51, 0, 170); }
.cm-s-inner .cm-bracket { color: rgb(153, 153, 119); }
.cm-s-inner .cm-tag { color: rgb(17, 119, 0); }
.cm-s-inner .cm-attribute { color: rgb(0, 0, 204); }
.cm-s-inner .cm-header, .cm-s-inner.cm-header { color: rgb(0, 0, 255); }
.cm-s-inner .cm-quote, .cm-s-inner.cm-quote { color: rgb(0, 153, 0); }
.cm-s-inner .cm-hr, .cm-s-inner.cm-hr { color: rgb(153, 153, 153); }
.cm-s-inner .cm-link, .cm-s-inner.cm-link { color: rgb(0, 0, 204); }
.cm-negative { color: rgb(221, 68, 68); }
.cm-positive { color: rgb(34, 153, 34); }
.cm-header, .cm-strong { font-weight: 700; }
.cm-del { text-decoration: line-through; }
.cm-em { font-style: italic; }
.cm-link { text-decoration: underline; }
.cm-error { color: red; }
.cm-invalidchar { color: red; }
.cm-constant { color: rgb(38, 139, 210); }
.cm-defined { color: rgb(181, 137, 0); }
div.CodeMirror span.CodeMirror-matchingbracket { color: rgb(0, 255, 0); }
div.CodeMirror span.CodeMirror-nonmatchingbracket { color: rgb(255, 34, 34); }
.cm-s-inner .CodeMirror-activeline-background { background: inherit; }
.CodeMirror { position: relative; overflow: hidden; }
.CodeMirror-scroll { height: 100%; outline: 0px; position: relative; box-sizing: content-box; background: inherit; }
.CodeMirror-sizer { position: relative; }
.CodeMirror-gutter-filler, .CodeMirror-hscrollbar, .CodeMirror-scrollbar-filler, .CodeMirror-vscrollbar { position: absolute; z-index: 6; display: none; }
.CodeMirror-vscrollbar { right: 0px; top: 0px; overflow: hidden; }
.CodeMirror-hscrollbar { bottom: 0px; left: 0px; overflow: hidden; }
.CodeMirror-scrollbar-filler { right: 0px; bottom: 0px; }
.CodeMirror-gutter-filler { left: 0px; bottom: 0px; }
.CodeMirror-gutters { position: absolute; left: 0px; top: 0px; padding-bottom: 30px; z-index: 3; }
.CodeMirror-gutter { white-space: normal; height: 100%; box-sizing: content-box; padding-bottom: 30px; margin-bottom: -32px; display: inline-block; }
.CodeMirror-gutter-wrapper { position: absolute; z-index: 4; background: 0px 0px !important; border: none !important; }
.CodeMirror-gutter-background { position: absolute; top: 0px; bottom: 0px; z-index: 4; }
.CodeMirror-gutter-elt { position: absolute; cursor: default; z-index: 4; }
.CodeMirror-lines { cursor: text; }
.CodeMirror pre { border-radius: 0px; border-width: 0px; background: 0px 0px; font-family: inherit; font-size: inherit; margin: 0px; white-space: pre; overflow-wrap: normal; color: inherit; z-index: 2; position: relative; overflow: visible; }
.CodeMirror-wrap pre { overflow-wrap: break-word; white-space: pre-wrap; word-break: normal; }
.CodeMirror-code pre { border-right: 30px solid transparent; width: fit-content; }
.CodeMirror-wrap .CodeMirror-code pre { border-right: none; width: auto; }
.CodeMirror-linebackground { position: absolute; left: 0px; right: 0px; top: 0px; bottom: 0px; z-index: 0; }
.CodeMirror-linewidget { position: relative; z-index: 2; overflow: auto; }
.CodeMirror-wrap .CodeMirror-scroll { overflow-x: hidden; }
.CodeMirror-measure { position: absolute; width: 100%; height: 0px; overflow: hidden; visibility: hidden; }
.CodeMirror-measure pre { position: static; }
.CodeMirror div.CodeMirror-cursor { position: absolute; visibility: hidden; border-right: none; width: 0px; }
.CodeMirror div.CodeMirror-cursor { visibility: hidden; }
.CodeMirror-focused div.CodeMirror-cursor { visibility: inherit; }
.cm-searching { background: rgba(255, 255, 0, 0.4); }
@media print {
  .CodeMirror div.CodeMirror-cursor { visibility: hidden; }
}


:root { --side-bar-bg-color: #fafafa; --control-text-color: #777; }
html { font-size: 16px; }
body { font-family: "Open Sans", "Clear Sans", "Helvetica Neue", Helvetica, Arial, sans-serif; color: rgb(51, 51, 51); line-height: 1.6; }
#write { max-width: 860px; margin: 0px auto; padding: 30px 30px 100px; }
#write > ul:first-child, #write > ol:first-child { margin-top: 30px; }
a { color: rgb(65, 131, 196); }
h1, h2, h3, h4, h5, h6 { position: relative; margin-top: 1rem; margin-bottom: 1rem; font-weight: bold; line-height: 1.4; cursor: text; }
h1:hover a.anchor, h2:hover a.anchor, h3:hover a.anchor, h4:hover a.anchor, h5:hover a.anchor, h6:hover a.anchor { text-decoration: none; }
h1 tt, h1 code { font-size: inherit; }
h2 tt, h2 code { font-size: inherit; }
h3 tt, h3 code { font-size: inherit; }
h4 tt, h4 code { font-size: inherit; }
h5 tt, h5 code { font-size: inherit; }
h6 tt, h6 code { font-size: inherit; }
h1 { padding-bottom: 0.3em; font-size: 2.25em; line-height: 1.2; border-bottom: 1px solid rgb(238, 238, 238); }
h2 { padding-bottom: 0.3em; font-size: 1.75em; line-height: 1.225; border-bottom: 1px solid rgb(238, 238, 238); }
h3 { font-size: 1.5em; line-height: 1.43; }
h4 { font-size: 1.25em; }
h5 { font-size: 1em; }
h6 { font-size: 1em; color: rgb(119, 119, 119); }
p, blockquote, ul, ol, dl, table { margin: 0.8em 0px; }
li > ol, li > ul { margin: 0px; }
hr { height: 2px; padding: 0px; margin: 16px 0px; background-color: rgb(231, 231, 231); border: 0px none; overflow: hidden; box-sizing: content-box; }
li p.first { display: inline-block; }
ul, ol { padding-left: 30px; }
ul:first-child, ol:first-child { margin-top: 0px; }
ul:last-child, ol:last-child { margin-bottom: 0px; }
blockquote { border-left: 4px solid rgb(223, 226, 229); padding: 0px 15px; color: rgb(119, 119, 119); }
blockquote blockquote { padding-right: 0px; }
table { padding: 0px; word-break: initial; }
table tr { border-top: 1px solid rgb(223, 226, 229); margin: 0px; padding: 0px; }
table tr:nth-child(2n), thead { background-color: rgb(248, 248, 248); }
table tr th { font-weight: bold; border-width: 1px 1px 0px; border-top-style: solid; border-right-style: solid; border-left-style: solid; border-top-color: rgb(223, 226, 229); border-right-color: rgb(223, 226, 229); border-left-color: rgb(223, 226, 229); border-image: initial; border-bottom-style: initial; border-bottom-color: initial; margin: 0px; padding: 6px 13px; }
table tr td { border: 1px solid rgb(223, 226, 229); margin: 0px; padding: 6px 13px; }
table tr th:first-child, table tr td:first-child { margin-top: 0px; }
table tr th:last-child, table tr td:last-child { margin-bottom: 0px; }
.CodeMirror-lines { padding-left: 4px; }
.code-tooltip { box-shadow: rgba(0, 28, 36, 0.3) 0px 1px 1px 0px; border-top: 1px solid rgb(238, 242, 242); }
.md-fences, code, tt { border: 1px solid rgb(231, 234, 237); background-color: rgb(248, 248, 248); border-radius: 3px; padding: 2px 4px 0px; font-size: 0.9em; }
code { background-color: rgb(243, 244, 244); padding: 0px 2px; }
.md-fences { margin-bottom: 15px; margin-top: 15px; padding-top: 8px; padding-bottom: 6px; }
.md-task-list-item > input { margin-left: -1.3em; }
@media print {
  html { font-size: 13px; }
  table, pre { break-inside: avoid; }
  pre { overflow-wrap: break-word; }
}
.md-fences { background-color: rgb(248, 248, 248); }
#write pre.md-meta-block { padding: 1rem; font-size: 85%; line-height: 1.45; background-color: rgb(247, 247, 247); border: 0px; border-radius: 3px; color: rgb(119, 119, 119); margin-top: 0px !important; }
.mathjax-block > .code-tooltip { bottom: 0.375rem; }
.md-mathjax-midline { background: rgb(250, 250, 250); }
#write > h3.md-focus::before { left: -1.5625rem; top: 0.375rem; }
#write > h4.md-focus::before { left: -1.5625rem; top: 0.285714rem; }
#write > h5.md-focus::before { left: -1.5625rem; top: 0.285714rem; }
#write > h6.md-focus::before { left: -1.5625rem; top: 0.285714rem; }
.md-image > .md-meta { border-radius: 3px; padding: 2px 0px 0px 4px; font-size: 0.9em; color: inherit; }
.md-tag { color: rgb(167, 167, 167); opacity: 1; }
.md-toc { margin-top: 20px; padding-bottom: 20px; }
.sidebar-tabs { border-bottom: none; }
#typora-quick-open { border: 1px solid rgb(221, 221, 221); background-color: rgb(248, 248, 248); }
#typora-quick-open-item { background-color: rgb(250, 250, 250); border-color: rgb(254, 254, 254) rgb(229, 229, 229) rgb(229, 229, 229) rgb(238, 238, 238); border-style: solid; border-width: 1px; }
.on-focus-mode blockquote { border-left-color: rgba(85, 85, 85, 0.12); }
header, .context-menu, .megamenu-content, footer { font-family: "Segoe UI", Arial, sans-serif; }
.file-node-content:hover .file-node-icon, .file-node-content:hover .file-node-open-state { visibility: visible; }
.mac-seamless-mode #typora-sidebar { background-color: var(--side-bar-bg-color); }
.md-lang { color: rgb(180, 101, 77); }
.html-for-mac .context-menu { --item-hover-bg-color: #E6F0FE; }
#md-notification .btn { border: 0px; }
.dropdown-menu .divider { border-color: rgb(229, 229, 229); }
.ty-preferences .window-content { background-color: rgb(250, 250, 250); }
.ty-preferences .nav-group-item.active { color: white; background: rgb(153, 153, 153); }


</style>
</head>
<body class='typora-export os-windows' >
<div  id='write'  class = 'is-node'><h1><a name="目录" class="md-header-anchor"></a><span>目录：</span></h1><div class='md-toc' mdtype='toc'><p class="md-toc-content" role="list"><span role="listitem" class="md-toc-item md-toc-h1" data-ref="n0"><a class="md-toc-inner" href="#目录">目录：</a></span><span role="listitem" class="md-toc-item md-toc-h1" data-ref="n3"><a class="md-toc-inner" href="#深度学习">深度学习</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n4"><a class="md-toc-inner" href="#1-训练">1. 训练</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n5"><a class="md-toc-inner" href="#1-1-为什么用交叉熵损失函数">1. 1 为什么用交叉熵损失函数？</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n14"><a class="md-toc-inner" href="#12-交叉熵损失的求导">1.2 交叉熵损失的求导</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n23"><a class="md-toc-inner" href="#13-怎么防止过拟合和欠拟合">1.3 怎么防止过拟合和欠拟合？</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n43"><a class="md-toc-inner" href="#14-l1和l2正则化">1.4 L1和L2正则化</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n63"><a class="md-toc-inner" href="#15-batch-normalization">1.5 Batch Normalization</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n92"><a class="md-toc-inner" href="#16-几种normalization方法">1.6 几种normalization方法</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n119"><a class="md-toc-inner" href="#17-几种优化器">1.7 几种优化器</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n146"><a class="md-toc-inner" href="#18-几种学习率衰减方法">1.8 几种学习率衰减方法</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n169"><a class="md-toc-inner" href="#19-几种参数初始化方法">1.9 几种参数初始化方法</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n185"><a class="md-toc-inner" href="#110-几种损失函数">1.10 几种损失函数</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n198"><a class="md-toc-inner" href="#111-为什么需要非线性激活函数">1.11 为什么需要非线性激活函数？</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n224"><a class="md-toc-inner" href="#111-几种激活函数及其导数">1.11 几种激活函数及其导数</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n227"><a class="md-toc-inner" href="#112-指定训练用gpu">1.12 指定训练用GPU</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n239"><a class="md-toc-inner" href="#113-maxpooling-怎么反向传播">1.13 maxpooling 怎么反向传播</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n243"><a class="md-toc-inner" href="#114-梯度消失和梯度爆炸的原因和解决">1.14 梯度消失和梯度爆炸的原因和解决</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n254"><a class="md-toc-inner" href="#115-感受野计算">1.15 感受野计算</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n257"><a class="md-toc-inner" href="#116-正负样本不均衡时的解决方案">1.16 正负样本不均衡时的解决方案</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n268"><a class="md-toc-inner" href="#117--加速网络收敛">1.17  加速网络收敛</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n272"><a class="md-toc-inner" href="#118-网络不收敛怎么办">1.18 网络不收敛怎么办</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n282"><a class="md-toc-inner" href="#2-数据">2. 数据</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n283"><a class="md-toc-inner" href="#21-数据扩增的方法">2.1 数据扩增的方法</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n291"><a class="md-toc-inner" href="#22-怎么发现不好的数据">2.2 怎么发现不好的数据？</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n294"><a class="md-toc-inner" href="#23-什么样的数据集不适合用深度学习">2.3 什么样的数据集不适合用深度学习?</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n297"><a class="md-toc-inner" href="#24-resize的方法">2.4 resize的方法</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n320"><a class="md-toc-inner" href="#3-代码">3. 代码</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n321"><a class="md-toc-inner" href="#31-手写mnist分类">3.1 手写MNIST分类</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n332"><a class="md-toc-inner" href="#31-mobilenet-v1">3.1 mobilenet V1</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n334"><a class="md-toc-inner" href="#32-用numpy实现分类器">3.2 用numpy实现分类器</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n338"><a class="md-toc-inner" href="#33-tfnamescope和tfvariablescope">3.3 tf.name_scope()和tf.variable_scope()</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n353"><a class="md-toc-inner" href="#34-tfvariable和tfgetvariable">3.4 tf.Variable()和tf.get_variable()</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n359"><a class="md-toc-inner" href="#4-基础问答">4. 基础问答</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n360"><a class="md-toc-inner" href="#41-分类和回归有什么区别">4.1 分类和回归有什么区别？</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n364"><a class="md-toc-inner" href="#42-简述svm">4.2 简述SVM</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n368"><a class="md-toc-inner" href="#43-简述k-means">4.3 简述K-Means</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n375"><a class="md-toc-inner" href="#44-resnet">4.4 ResNet</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n377"><a class="md-toc-inner" href="#45-mobilenet-v1-v2-v3">4.5 mobilenet V1 V2 V3</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n380"><a class="md-toc-inner" href="#46-交叉验证">4.6 交叉验证</a></span><span role="listitem" class="md-toc-item md-toc-h1" data-ref="n401"><a class="md-toc-inner" href="#计算机视觉">计算机视觉</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n402"><a class="md-toc-inner" href="#1-目标检测">1. 目标检测</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n403"><a class="md-toc-inner" href="#11-相关研究">1.1 相关研究</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n412"><a class="md-toc-inner" href="#11-目标检测中评价指标">1.1 目标检测中评价指标</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n435"><a class="md-toc-inner" href="#12-focal-loss">1.2 focal loss</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n441"><a class="md-toc-inner" href="#13-smooth-l2">1.3 smooth L2</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n443"><a class="md-toc-inner" href="#14-边界框回归ground-truth计算">1.4 边界框回归ground truth计算</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n445"><a class="md-toc-inner" href="#15-roipooling--roiwarp-roialign-preciseroi">1.5 ROIPooling  RoIWarp RoIAlign PreciseRoI</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n447"><a class="md-toc-inner" href="#16-得到auc的两种办法">1.6 得到AUC的两种办法</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n449"><a class="md-toc-inner" href="#16-nms原理">1.6 NMS原理</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n469"><a class="md-toc-inner" href="#2-语义分割">2. 语义分割</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n470"><a class="md-toc-inner" href="#21-相关研究">2.1 相关研究</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n474"><a class="md-toc-inner" href="#22-评价指标">2.2 评价指标</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n478"><a class="md-toc-inner" href="#23-dice-loss">2.3 DICE loss</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n486"><a class="md-toc-inner" href="#3-目标跟踪">3. 目标跟踪</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n487"><a class="md-toc-inner" href="#31-孪生网络">3.1 孪生网络</a></span><span role="listitem" class="md-toc-item md-toc-h3" data-ref="n489"><a class="md-toc-inner" href="#32-相关研究">3.2 相关研究</a></span><span role="listitem" class="md-toc-item md-toc-h1" data-ref="n491"><a class="md-toc-inner" href="#python">Python</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n492"><a class="md-toc-inner" href="#1-python深拷贝和浅拷贝区别">1. python深拷贝和浅拷贝区别</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n502"><a class="md-toc-inner" href="#2-多态和鸭子类型">2. 多态和鸭子类型</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n504"><a class="md-toc-inner" href="#3-列表和元组的区别">3. 列表和元组的区别</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n521"><a class="md-toc-inner" href="#4-斐波那契数列">4. 斐波那契数列</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n523"><a class="md-toc-inner" href="#5-装饰器">5. 装饰器</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n525"><a class="md-toc-inner" href="#6-生成器-迭代器">6. 生成器 迭代器</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n527"><a class="md-toc-inner" href="#7-lambda匿名函数">7. lambda匿名函数</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n530"><a class="md-toc-inner" href="#8-列表中append和extend方法的区别">8. 列表中append()和extend()方法的区别</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n533"><a class="md-toc-inner" href="#9-python中内置的数据结构有几种">9. python中内置的数据结构有几种？</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n539"><a class="md-toc-inner" href="#10-类中的new和init有啥区别">10. 类中的new和init有啥区别？</a></span><span role="listitem" class="md-toc-item md-toc-h1" data-ref="n550"><a class="md-toc-inner" href="#数据结构">数据结构</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n551"><a class="md-toc-inner" href="#1-快速排序">1. 快速排序</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n553"><a class="md-toc-inner" href="#2-堆排序">2. 堆排序</a></span><span role="listitem" class="md-toc-item md-toc-h2" data-ref="n555"><a class="md-toc-inner" href="#3-二叉树">3. 二叉树</a></span></p></div><h1><a name="深度学习" class="md-header-anchor"></a><span>深度学习</span></h1><h2><a name="1-训练" class="md-header-anchor"></a><span>1. 训练</span></h2><h3><a name="1-1-为什么用交叉熵损失函数" class="md-header-anchor"></a><span>1. 1 为什么用交叉熵损失函数？</span></h3><p><a href='https://blog.csdn.net/huwenxing0801/article/details/82791879' target='_blank' class='url'>https://blog.csdn.net/huwenxing0801/article/details/82791879</a></p><p><span>概念：信息量、信息熵、相对熵、交叉熵</span></p><p><span>梯度下降的目的，直白地说：是减小真实值和预测值的距离，而损失函数用来度量真实值和预测值之间距离</span></p><p><img src="./image/1/1-1.1-1.png" referrerpolicy="no-referrer" alt="1552734925952"></p><p><img src="./image/1/1-1.1-2.png" referrerpolicy="no-referrer" alt="1552734904253"></p><p><span>从以上公式可以看出：均方差对参数的偏导的结果都乘了sigmoid的导数，而sigmoid导数在其变量值很大或很小时趋近于0，所以偏导数很有可能接近于0。可知，偏导很小时，参数更新速度会变得很慢，而当偏导接近于0时，参数几乎就不更新了。</span></p><p><span>反观交叉熵对参数的偏导就没有sigmoid导数，所以不存在这个问题。这就是选择交叉熵而不选择均方差的原因</span></p><p><a href='#目录'><span>回到顶部</span></a></p><h3><a name="12-交叉熵损失的求导" class="md-header-anchor"></a><span>1.2 交叉熵损失的求导</span></h3><p><img src="./image/1/1-1.2-1.png" referrerpolicy="no-referrer" alt="1559289490702"></p><p><img src="./image/1/1-1.2-2.png" referrerpolicy="no-referrer" alt="1559289029109"></p><p><span>三个重点求导记住：</span></p><p><span>1）对sigmoid激活a的求导：a(1-a)       a = f(z)</span></p><p><span>2）对乘加操作z的求导：a-y         y是标签    ★★★★</span></p><p><span>3）对权重w的求导：x(a-y)</span></p><p><span>推荐博客：</span><a href='https://blog.csdn.net/zhishengqianjun/article/details/75303820' target='_blank' class='url'>https://blog.csdn.net/zhishengqianjun/article/details/75303820</a></p><p><a href='#目录'><span>回到顶部</span></a></p><h3><a name="13-怎么防止过拟合和欠拟合" class="md-header-anchor"></a><span>1.3 怎么防止过拟合和欠拟合？</span></h3><p><strong><span>过拟合：</span></strong></p><ol start='' ><li><p><strong><span>数据集</span></strong><span>上：获取更多的数据，添加噪声数据，将数据集分为训练集、交叉验证集、测试集</span></p></li><li><p><span>batch normalization（慎说）</span></p></li><li><p><strong><span>正则化：</span></strong></p><p><span>1）参数正则化方法：L1和L2正则化</span></p><p><span>2）经验正则化方法：dropout，提前停止（early stopping）</span></p></li></ol><p><strong><span>欠拟合：</span></strong></p><ol start='' ><li><span>添加其他特征项。组合、泛化、相关性、上下文特征、平台特征等特征是特征添加的重要手段，有时候特征项不够会导致模型欠拟合。</span></li><li><span>可以增加模型的复杂程度。</span></li><li><span>减小正则化系数。正则化的目的是用来防止过拟合的，但是现在模型出现了欠拟合，则需要减少正则化参数。</span></li></ol><p><a href='#目录'><span>回到顶部</span></a></p><h3><a name="14-l1和l2正则化" class="md-header-anchor"></a><span>1.4 L1和L2正则化</span></h3><p><span>也可以称之为权重衰减(weight decay)</span></p><p><span>什么是正则化？所谓正则化，它的目标就是要同时让</span><strong><span>经验风险</span></strong><span>和</span><strong><span>模型复杂度</span></strong><span>较小。</span></p><p><a href='https://mp.weixin.qq.com/s/-vmQpmrIfYCwp_ttoLbAJg' target='_blank' class='url'>https://mp.weixin.qq.com/s/-vmQpmrIfYCwp_ttoLbAJg</a></p><p><a href='https://blog.csdn.net/program_developer/article/details/80867468' target='_blank' class='url'>https://blog.csdn.net/program_developer/article/details/80867468</a></p><p><span>L1-最小绝对偏差(LAD)和L2-最小二乘误差(LS)，</span></p><p><img src="./image/1/1-1.4-1.png" referrerpolicy="no-referrer" alt="img"></p><p><span>lambda是</span><strong><span>正则化系数</span></strong><span>，也可以是</span><strong><span>正则化率</span></strong><span>，也可以是</span><strong><span>衰减率</span></strong><span>，非常小，在选择其值时，试图在模型的简单性和拟合训练数据之间达到最佳点。n是样本大小。代价函数：</span></p><p><img src="./image/1/1-1.4-2.png" referrerpolicy="no-referrer" alt="20180630161015526"></p><p><span>求导： 对b没有影响</span></p><p><img src="./image/1/1-1.4-3.png" referrerpolicy="no-referrer" alt="img"></p><p><span>参数更新： 可以看出，w更新前，会先衰减一点点</span></p><p><img src="./image/1/1-1.4-4.png" referrerpolicy="no-referrer" alt="img"></p><p><strong><span>正则化作用：</span></strong></p><p><span>（1）从模型的复杂度上解释：更小的权值w，从某种意义上说，表示网络的</span><strong><span>复杂度更低</span></strong><span>，对数据的拟合更好（这个法则也叫做奥卡姆剃刀），而在实际应用中，也验证了这一点，L2正则化的效果往往好于未经正则化的效果。（2）从数学方面的解释：过拟合的时候，拟合函数的</span><strong><span>系数往往非常大</span></strong><span>，为什么？就是拟合函数需要顾忌每一个点，最终形成的拟合函数波动很大，这就造成过拟合。在某些很小的区间里，函数值的变化很剧烈。这就意味着函数在某些小区间里的导数值（绝对值）非常大，由于自变量值可大可小，所以只有系数足够大，才能保证导数值很大。而正则化是通过</span><strong><span>约束参数的范数使其不要太大</span></strong><span>，所以可以在一定程度上减少过拟合情况。</span></p><p><strong><span>L1 正则的规范化目标是造成参数的稀疏化，就是争取达到让大量参数值取得 0 值的效果，而 L2 正则的规范化目标是有效减小原始参数值的大小</span></strong><span>。</span></p><p><span>假定你的数据分布是稀疏的，就用L1正则</span></p><p><span>周志华西瓜书253页</span>
<span>总结一点就是</span>
<span>L1范数有棱角，和优化目标函数相切的点在各分量上要么有值要么为0</span>
<span>L2范数比较圆滑，喜欢每个分量上都分一点，比起L1，L2更加平滑稳定</span></p><p><img src="./image/1/1-1.4-5.jpg" referrerpolicy="no-referrer" alt="img"></p><p><a href='#目录'><span>回到顶部</span></a></p><h3><a name="15-batch-normalization" class="md-header-anchor"></a><span>1.5 Batch Normalization</span></h3><p><span>一个batch通过一个神经元，得到的值，然后计算的均值和方差（如果是原始输入值，计算在该神经元上输入的均值方差）。有几个神经元，就有几组均值和方差。</span></p><p><span>&#39;decay&#39; 滑动平均</span>
<span>&#39;center&#39; β</span>
<span>&#39;scale&#39; γ</span>
<span>&#39;epsilon&#39; 计算方差时加入的 防止为零</span></p><p><span>对每个元素进行归一化后，再进行尺度缩放和偏移操作，这样可以变换回原始的分布，实现恒等变换，这样的目的是为了</span><strong><span>补偿网络的非线性表达能力</span></strong><span>，因为经过标准化之后，偏移量丢失。具体的表达如下：</span></p><div contenteditable="false" spellcheck="false" class="mathjax-block md-end-block md-math-block md-rawblock" id="mathjax-n67" cid="n67" mdtype="math_block"><div class="md-rawblock-container md-math-container" tabindex="-1"><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-1-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="15.794ex" height="3.161ex" viewBox="0 -956.9 6800.3 1361" role="img" focusable="false" style="vertical-align: -0.938ex; max-width: 100%;"><defs><path stroke-width="0" id="E1-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path stroke-width="0" id="E1-MJMATHI-3B3" d="M31 249Q11 249 11 258Q11 275 26 304T66 365T129 418T206 441Q233 441 239 440Q287 429 318 386T371 255Q385 195 385 170Q385 166 386 166L398 193Q418 244 443 300T486 391T508 430Q510 431 524 431H537Q543 425 543 422Q543 418 522 378T463 251T391 71Q385 55 378 6T357 -100Q341 -165 330 -190T303 -216Q286 -216 286 -188Q286 -138 340 32L346 51L347 69Q348 79 348 100Q348 257 291 317Q251 355 196 355Q148 355 108 329T51 260Q49 251 47 251Q45 249 31 249Z"></path><path stroke-width="0" id="E1-MJMAIN-22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path><path stroke-width="0" id="E1-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path stroke-width="0" id="E1-MJMAIN-2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"></path><path stroke-width="0" id="E1-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path stroke-width="0" id="E1-MJMATHI-3B2" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E1-MJMATHI-79" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="692" y="-213"></use><use xlink:href="#E1-MJMAIN-3D" x="1111" y="0"></use><g transform="translate(2167,0)"><use xlink:href="#E1-MJMATHI-3B3" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="732" y="-213"></use></g><use xlink:href="#E1-MJMAIN-22C5" x="3251" y="0"></use><g transform="translate(3751,0)"><use xlink:href="#E1-MJMATHI-78" x="0" y="0"></use><g transform="translate(572,344)"><use transform="scale(0.5)" xlink:href="#E1-MJMAIN-2032" x="0" y="513"></use></g><use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="808" y="-429"></use></g><use xlink:href="#E1-MJMAIN-2B" x="4890" y="0"></use><g transform="translate(5890,0)"><use xlink:href="#E1-MJMATHI-3B2" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="800" y="-213"></use></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-1">y_i = \gamma_i \cdot x^{'}_i+\beta_i</script></div></div><p><span> </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.127ex" height="3.161ex" viewBox="0 -956.9 916 1361" role="img" focusable="false" style="vertical-align: -0.938ex;"><defs><path stroke-width="0" id="E7-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path stroke-width="0" id="E7-MJMAIN-2032" d="M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z"></path><path stroke-width="0" id="E7-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E7-MJMATHI-78" x="0" y="0"></use><g transform="translate(572,344)"><use transform="scale(0.5)" xlink:href="#E7-MJMAIN-2032" x="0" y="513"></use></g><use transform="scale(0.707)" xlink:href="#E7-MJMATHI-69" x="808" y="-429"></use></g></svg></span><script type="math/tex">x^{'}_i</script><span> 为零均值归一化后的值。由于归一化后的值基本会被限制在正态分布下，使得网络的表达能力下降。为解决该问题，引入两个新的参数：γ,β.</span></p><p><span>假如gamma等于方差，beta等于均值，就实现了恒等变换。从某种意义上来说，gamma和beta代表的其实是</span><strong><span>输入数据分布的方差和偏移</span></strong><span>。对于没有BN的网络，这两个值与前一层网络带来的非线性性质有关，而经过变换后，就跟前面一层无关，变成了当前层的一个学习参数，这更加有利于优化并且不会降低网络的能力。</span></p><p><span>CNN中BN的操作是在</span><strong><span>各个特征维度之间单独进行</span></strong><span>，也就是说各个通道是分别进行Batch Normalization操作的。如果输出的blob大小为(N,C,H,W)，那么在每一层normalization就是基于NxHxW个数值进行求平均以及方差的操作。</span></p><p><a href='https://mp.weixin.qq.com/s/GcyuYOIZLvGfq4_FoVDbUA' target='_blank' class='url'>https://mp.weixin.qq.com/s/GcyuYOIZLvGfq4_FoVDbUA</a></p><p><a href='https://blog.csdn.net/u010899985/article/details/82251932' target='_blank' class='url'>https://blog.csdn.net/u010899985/article/details/82251932</a></p><p><strong><span>BN带来的好处：</span></strong></p><p><span>(1) 减轻了对参数初始化的依赖，利于调参，使网络学习更加稳定。</span></p><p><span>(2) 调整了数据的分布，它让每一层的输出归一化到了均值为0方差为1的分布，这保证了梯度的有效性</span></p><p><span>(3) 加速训练，可以使用更高的学习率。</span></p><p><span>(4) BN一定程度上增加了泛化能力，具有一定的正则化效果，dropout等技术可以去掉。</span></p><p><strong><span>BN的缺陷</span></strong></p><p><span>batch normalization依赖于batch的大小，当batch值很小时，计算的均值和方差不稳定。</span></p><p><strong><span>BN训练测试的区别</span></strong></p><p><span>训练时，用的是批数据的均值和方差</span></p><p><span>训练结束后，对整个训练集计算了所有批数据的mean和var的平均无偏估计（也可以滑动平均），</span></p><p><span>作为最终的mean和var存储到了模型中。测试的时候直接从模型中读取mean和var进行计算。</span></p><p><strong><span>BN为什么可以加速收敛？</span></strong></p><p><span>在深层网络训练的过程中，由于网络中参数变化而引起内部结点数据分布发生变化</span></p><p><span>（1）上层网络需要不停调整来</span><strong><span>适应输入数据分布的变化</span></strong><span>，导致网络学习速度的降低</span></p><p><span>（2）网络的训练过程容易陷入</span><strong><span>梯度饱和区</span></strong><span>，参收更新变慢，减缓网络收敛速度</span></p><p><strong><span>BN为什么可以代替dropout？</span></strong></p><p><span>在Batch Normalization中，由于我们使用mini-batch的均值与方差作为对整体训练样本均值与方差的</span><strong><span>估计</span></strong><span>，尽管每一个batch中的数据都是从总体样本中抽样得到，但不同mini-batch的均值与方差会有所不同，这就为网络的学习过程中</span><strong><span>增加了随机噪音</span></strong><span>，与Dropout通过关闭神经元给网络训练带来噪音类似，在一定程度上对模型起到了正则化的效果。</span></p><p><span>参考：</span><a href='https://zhuanlan.zhihu.com/p/34879333' target='_blank' class='url'>https://zhuanlan.zhihu.com/p/34879333</a></p><p><a href='#目录'><span>回到顶部</span></a></p><h3><a name="16-几种normalization方法" class="md-header-anchor"></a><span>1.6 几种normalization方法</span></h3><p><span>先说下两种</span><strong><span>归一化</span></strong><span>：</span></p><ol start='' ><li><strong><span>线性归一化</span></strong><span>：</span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="13.771ex" height="3.628ex" viewBox="0 -1007.2 5929 1562" role="img" focusable="false" style="vertical-align: -1.289ex;"><defs><path stroke-width="0" id="E8-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E8-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E8-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path stroke-width="0" id="E8-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path stroke-width="0" id="E8-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path stroke-width="0" id="E8-MJMATHI-6D" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E8-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E8-MJMATHI-61" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E8-MJMATHI-79" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E8-MJMATHI-69" x="692" y="-213"></use><use xlink:href="#E8-MJMAIN-3D" x="1111" y="0"></use><g transform="translate(1889,0)"><g transform="translate(397,0)"><rect stroke="none" width="3521" height="60" x="0" y="220"></rect><g transform="translate(468,515)"><use transform="scale(0.707)" xlink:href="#E8-MJMATHI-78" x="0" y="0"></use><use transform="scale(0.5)" xlink:href="#E8-MJMATHI-69" x="808" y="-213"></use><use transform="scale(0.707)" xlink:href="#E8-MJMAIN-2212" x="915" y="0"></use><g transform="translate(1197,0)"><use transform="scale(0.707)" xlink:href="#E8-MJMATHI-78" x="0" y="0"></use><g transform="translate(404,-107)"><use transform="scale(0.5)" xlink:href="#E8-MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.5)" xlink:href="#E8-MJMATHI-69" x="878" y="0"></use><use transform="scale(0.5)" xlink:href="#E8-MJMATHI-6E" x="1223" y="0"></use></g></g></g><g transform="translate(60,-345)"><use transform="scale(0.707)" xlink:href="#E8-MJMATHI-78" x="0" y="0"></use><g transform="translate(404,-107)"><use transform="scale(0.5)" xlink:href="#E8-MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.5)" xlink:href="#E8-MJMATHI-61" x="878" y="0"></use><use transform="scale(0.5)" xlink:href="#E8-MJMATHI-78" x="1407" y="0"></use></g><use transform="scale(0.707)" xlink:href="#E8-MJMAIN-2212" x="2071" y="0"></use><g transform="translate(2014,0)"><use transform="scale(0.707)" xlink:href="#E8-MJMATHI-78" x="0" y="0"></use><g transform="translate(404,-107)"><use transform="scale(0.5)" xlink:href="#E8-MJMATHI-6D" x="0" y="0"></use><use transform="scale(0.5)" xlink:href="#E8-MJMATHI-69" x="878" y="0"></use><use transform="scale(0.5)" xlink:href="#E8-MJMATHI-6E" x="1223" y="0"></use></g></g></g></g></g></g></svg></span><script type="math/tex">y_i = \frac{x_i-x_{min}}{x_{max}-x_{min}}</script></li><li><strong><span>零均值归一化/Z-score标准化</span></strong><span>：</span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="9.643ex" height="3.511ex" viewBox="0 -1057.4 4151.7 1511.8" role="img" focusable="false" style="vertical-align: -1.055ex;"><defs><path stroke-width="0" id="E9-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E9-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E9-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path stroke-width="0" id="E9-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path stroke-width="0" id="E9-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path stroke-width="0" id="E9-MJMATHI-3BC" d="M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z"></path><path stroke-width="0" id="E9-MJMATHI-3C3" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E9-MJMATHI-79" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E9-MJMATHI-69" x="692" y="-213"></use><use xlink:href="#E9-MJMAIN-3D" x="1111" y="0"></use><g transform="translate(1889,0)"><g transform="translate(397,0)"><rect stroke="none" width="1744" height="60" x="0" y="220"></rect><g transform="translate(60,556)"><use transform="scale(0.707)" xlink:href="#E9-MJMATHI-78" x="0" y="0"></use><use transform="scale(0.5)" xlink:href="#E9-MJMATHI-69" x="808" y="-213"></use><use transform="scale(0.707)" xlink:href="#E9-MJMAIN-2212" x="915" y="0"></use><use transform="scale(0.707)" xlink:href="#E9-MJMATHI-3BC" x="1693" y="0"></use></g><use transform="scale(0.707)" xlink:href="#E9-MJMATHI-3C3" x="947" y="-488"></use></g></g></g></svg></span><script type="math/tex">y_i = \frac{x_i-\mu}{\sigma}</script></li></ol><p><strong><span>为什么要归一化？</span></strong></p><ol start='' ><li><span>为了后面数据处理的方便，归一化的确可以避免一些不必要的数值问题。</span></li><li><span>为了程序运行时收敛加快。</span></li><li><span>同一量纲。样本数据的评价标准不一样，需要对其量纲化，统一评价标准。这算是应用层面的需求。</span></li><li><span>避免神经元饱和。啥意思？就是当神经元的激活在接近 0 或者 1 时会饱和，在这些区域，梯度几乎为 0，这样，在反向传播过程中，局部梯度就会接近 0，这会有效地“杀死”梯度。</span></li><li><span>保证输出数据中数值小的不被吞食。 </span></li></ol><p><span>Batch Normalization是NxHxW，Layer Normalization是CxHxW，Instance Normalization是HxW，Group Normalization是GxHxW</span></p><p><strong><span>Layer Normalization</span></strong></p><p><span>抛弃对batch的依赖，也就是每一个样本都单独进行normalization，同时各个通道都要用到。跟Batch Normalization仅针对单个神经元不同，Layer Normalization</span><strong><span>考虑了神经网络中一层的神经元</span></strong></p><p><strong><span>Instance Normalization</span></strong></p><p>&nbsp;</p><p><strong><span>Group Normalization</span></strong></p><p>&nbsp;</p><p><a href='#目录'><span>回到顶部</span></a></p><h3><a name="17-几种优化器" class="md-header-anchor"></a><span>1.7 几种优化器</span></h3><p><span>SGD Momentum Adagrad Adadelta RMSprop Adam</span></p><p><a href='https://blog.csdn.net/fzp95/article/details/83018744' target='_blank' class='url'>https://blog.csdn.net/fzp95/article/details/83018744</a></p><p><span>强推：</span><a href='https://blog.csdn.net/u012328159/article/details/80311892' target='_blank' class='url'>https://blog.csdn.net/u012328159/article/details/80311892</a></p><p><strong><span>1. SGD</span></strong></p><p><span>缺点：SGD并不是每次迭代都向着整体最优化方向，会造成严重的震荡。虽然包含一定的随机性，但是从期望上来看，它是等于正确的导数的。</span></p><p><strong><span>2. SGD with momentum</span></strong></p><p><span>在更新参数时加入了</span><strong><span>指数加权平均</span></strong><span>，momentum越大，之前梯度对现在的方向影响越大。</span></p><pre spellcheck="false" class="md-fences md-end-block ty-contain-cm modeLoaded" lang="python"><div class="CodeMirror cm-s-inner CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><span><span>​</span>x</span></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation" style=""><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">momentum</span> = <span class="cm-number">0.9</span></span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">vdW</span> = <span class="cm-number">0</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">vdb</span> = <span class="cm-number">0</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">for</span> <span class="cm-variable">i</span> <span class="cm-keyword">in</span> <span class="cm-builtin">range</span>(<span class="cm-variable">num_iter</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">vdW</span> = <span class="cm-variable">momentum</span><span class="cm-operator">*</span><span class="cm-variable">vdW</span> <span class="cm-operator">+</span> (<span class="cm-number">1</span> <span class="cm-operator">-</span> <span class="cm-variable">momentum</span>)<span class="cm-operator">*</span><span class="cm-variable">grads</span>[<span class="cm-string">'W'</span>]</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">params</span>[<span class="cm-string">'W'</span>] -= <span class="cm-variable">learning_rate</span><span class="cm-operator">*</span><span class="cm-variable">vdW</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="">​</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">vdb</span> = <span class="cm-variable">momentum</span><span class="cm-operator">*</span><span class="cm-variable">vdb</span> <span class="cm-operator">+</span> (<span class="cm-number">1</span> <span class="cm-operator">-</span> <span class="cm-variable">momentum</span>)<span class="cm-operator">*</span><span class="cm-variable">grads</span>[<span class="cm-string">'b'</span>]</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">params</span>[<span class="cm-string">'b'</span>] -= <span class="cm-variable">learning_rate</span><span class="cm-operator">*</span><span class="cm-variable">vdb</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 204px;"></div><div class="CodeMirror-gutters" style="display: none; height: 204px;"></div></div></div></pre><p><strong><span>3. AdaGrad</span></strong></p><p><span>每一次更新参数时，不同的参数使用不同的学习率</span></p><p><span>优点：对于梯度较大的参数，</span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.651ex" height="2.461ex" viewBox="0 -806.1 1141.3 1059.4" role="img" focusable="false" style="vertical-align: -0.588ex;"><defs><path stroke-width="0" id="E12-MJMATHI-47" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q492 659 471 656T418 643T357 615T294 567T236 496T189 394T158 260Q156 242 156 221Q156 173 170 136T206 79T256 45T308 28T353 24Q407 24 452 47T514 106Q517 114 529 161T541 214Q541 222 528 224T468 227H431Q425 233 425 235T427 254Q431 267 437 273H454Q494 271 594 271Q634 271 659 271T695 272T707 272Q721 272 721 263Q721 261 719 249Q714 230 709 228Q706 227 694 227Q674 227 653 224Q646 221 643 215T629 164Q620 131 614 108Q589 6 586 3Q584 1 581 1Q571 1 553 21T530 52Q530 53 528 52T522 47Q448 -22 322 -22Q201 -22 126 55T50 252Z"></path><path stroke-width="0" id="E12-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E12-MJMATHI-47" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E12-MJMATHI-74" x="1111" y="-213"></use></g></svg></span><script type="math/tex">G_t</script><span>相对较大，则</span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.297ex" height="3.861ex" viewBox="0 -806.1 2711.3 1662.6" role="img" focusable="false" style="vertical-align: -1.989ex;"><defs><path stroke-width="0" id="E11-MJMATHI-3B1" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path><path stroke-width="0" id="E11-MJMATHI-47" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q492 659 471 656T418 643T357 615T294 567T236 496T189 394T158 260Q156 242 156 221Q156 173 170 136T206 79T256 45T308 28T353 24Q407 24 452 47T514 106Q517 114 529 161T541 214Q541 222 528 224T468 227H431Q425 233 425 235T427 254Q431 267 437 273H454Q494 271 594 271Q634 271 659 271T695 272T707 272Q721 272 721 263Q721 261 719 249Q714 230 709 228Q706 227 694 227Q674 227 653 224Q646 221 643 215T629 164Q620 131 614 108Q589 6 586 3Q584 1 581 1Q571 1 553 21T530 52Q530 53 528 52T522 47Q448 -22 322 -22Q201 -22 126 55T50 252Z"></path><path stroke-width="0" id="E11-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path><path stroke-width="0" id="E11-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path stroke-width="0" id="E11-MJMATHI-3F5" d="M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z"></path><path stroke-width="0" id="E11-MJSZ1-221A" d="M263 249Q264 249 315 130T417 -108T470 -228L725 302Q981 837 982 839Q989 850 1001 850Q1008 850 1013 844T1020 832V826L741 243Q645 43 540 -176Q479 -303 469 -324T453 -348Q449 -350 436 -350L424 -349L315 -96Q206 156 205 156L171 130Q138 104 137 104L111 130L263 249Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g transform="translate(120,0)"><rect stroke="none" width="2471" height="60" x="0" y="220"></rect><use transform="scale(0.707)" xlink:href="#E11-MJMATHI-3B1" x="1427" y="582"></use><g transform="translate(60,-570)"><use transform="scale(0.707)" xlink:href="#E11-MJSZ1-221A" x="0" y="30"></use><rect stroke="none" width="1644" height="42" x="707" y="580"></rect><g transform="translate(707,0)"><use transform="scale(0.707)" xlink:href="#E11-MJMATHI-47" x="0" y="0"></use><use transform="scale(0.5)" xlink:href="#E11-MJMATHI-74" x="1111" y="-213"></use><use transform="scale(0.707)" xlink:href="#E11-MJMAIN-2B" x="1141" y="0"></use><use transform="scale(0.707)" xlink:href="#E11-MJMATHI-3F5" x="1919" y="0"></use></g></g></g></g></svg></span><script type="math/tex">\frac{\alpha}{\sqrt{G_t + \epsilon}}</script><span>较小，意味着学习率会变得较小。而对于梯度较小的参数，则效果相反。这样就可以使得参数在平缓的地方下降的稍微快些，不至于徘徊不前。</span></p><p><span>缺点：由于是累积梯度的平方，到后面</span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.651ex" height="2.461ex" viewBox="0 -806.1 1141.3 1059.4" role="img" focusable="false" style="vertical-align: -0.588ex;"><defs><path stroke-width="0" id="E12-MJMATHI-47" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q492 659 471 656T418 643T357 615T294 567T236 496T189 394T158 260Q156 242 156 221Q156 173 170 136T206 79T256 45T308 28T353 24Q407 24 452 47T514 106Q517 114 529 161T541 214Q541 222 528 224T468 227H431Q425 233 425 235T427 254Q431 267 437 273H454Q494 271 594 271Q634 271 659 271T695 272T707 272Q721 272 721 263Q721 261 719 249Q714 230 709 228Q706 227 694 227Q674 227 653 224Q646 221 643 215T629 164Q620 131 614 108Q589 6 586 3Q584 1 581 1Q571 1 553 21T530 52Q530 53 528 52T522 47Q448 -22 322 -22Q201 -22 126 55T50 252Z"></path><path stroke-width="0" id="E12-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E12-MJMATHI-47" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E12-MJMATHI-74" x="1111" y="-213"></use></g></svg></span><script type="math/tex">G_t</script><span>累计的比较大，会导致</span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="11.071ex" height="3.861ex" viewBox="0 -806.1 4766.9 1662.6" role="img" focusable="false" style="vertical-align: -1.989ex;"><defs><path stroke-width="0" id="E13-MJMATHI-3B1" d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path><path stroke-width="0" id="E13-MJMATHI-47" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q492 659 471 656T418 643T357 615T294 567T236 496T189 394T158 260Q156 242 156 221Q156 173 170 136T206 79T256 45T308 28T353 24Q407 24 452 47T514 106Q517 114 529 161T541 214Q541 222 528 224T468 227H431Q425 233 425 235T427 254Q431 267 437 273H454Q494 271 594 271Q634 271 659 271T695 272T707 272Q721 272 721 263Q721 261 719 249Q714 230 709 228Q706 227 694 227Q674 227 653 224Q646 221 643 215T629 164Q620 131 614 108Q589 6 586 3Q584 1 581 1Q571 1 553 21T530 52Q530 53 528 52T522 47Q448 -22 322 -22Q201 -22 126 55T50 252Z"></path><path stroke-width="0" id="E13-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path><path stroke-width="0" id="E13-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path stroke-width="0" id="E13-MJMATHI-3F5" d="M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z"></path><path stroke-width="0" id="E13-MJSZ1-221A" d="M263 249Q264 249 315 130T417 -108T470 -228L725 302Q981 837 982 839Q989 850 1001 850Q1008 850 1013 844T1020 832V826L741 243Q645 43 540 -176Q479 -303 469 -324T453 -348Q449 -350 436 -350L424 -349L315 -96Q206 156 205 156L171 130Q138 104 137 104L111 130L263 249Z"></path><path stroke-width="0" id="E13-MJMAIN-2192" d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"></path><path stroke-width="0" id="E13-MJMAIN-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g transform="translate(120,0)"><rect stroke="none" width="2471" height="60" x="0" y="220"></rect><use transform="scale(0.707)" xlink:href="#E13-MJMATHI-3B1" x="1427" y="582"></use><g transform="translate(60,-570)"><use transform="scale(0.707)" xlink:href="#E13-MJSZ1-221A" x="0" y="30"></use><rect stroke="none" width="1644" height="42" x="707" y="580"></rect><g transform="translate(707,0)"><use transform="scale(0.707)" xlink:href="#E13-MJMATHI-47" x="0" y="0"></use><use transform="scale(0.5)" xlink:href="#E13-MJMATHI-74" x="1111" y="-213"></use><use transform="scale(0.707)" xlink:href="#E13-MJMAIN-2B" x="1141" y="0"></use><use transform="scale(0.707)" xlink:href="#E13-MJMATHI-3F5" x="1919" y="0"></use></g></g></g><use xlink:href="#E13-MJMAIN-2192" x="2989" y="0"></use><use xlink:href="#E13-MJMAIN-30" x="4266" y="0"></use></g></svg></span><script type="math/tex">\frac{\alpha}{\sqrt{G_t + \epsilon}}\rightarrow0</script><span>，导致梯度消失。</span></p><pre spellcheck="false" class="md-fences md-end-block ty-contain-cm modeLoaded" lang="python"><div class="CodeMirror cm-s-inner CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation" style=""><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">for</span> <span class="cm-variable">i</span> <span class="cm-keyword">in</span> <span class="cm-builtin">range</span>(<span class="cm-variable">num_iter</span>):</span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">G_W</span> = <span class="cm-variable">grads</span>[<span class="cm-string">'W'</span>]<span class="cm-operator">**</span><span class="cm-number">2</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">params</span>[<span class="cm-string">'W'</span>] -= <span class="cm-variable">learning_rate</span><span class="cm-operator">*</span><span class="cm-variable">grads</span>[<span class="cm-string">'W'</span>]<span class="cm-operator">/</span>(<span class="cm-variable">np</span>.<span class="cm-property">sqrt</span>(<span class="cm-variable">G_W</span>) <span class="cm-operator">+</span> <span class="cm-variable">epsilon</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="">​</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">G_b</span> = <span class="cm-variable">grads</span>[<span class="cm-string">'b'</span>]<span class="cm-operator">**</span><span class="cm-number">2</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">params</span>[<span class="cm-string">'b'</span>] -= <span class="cm-variable">learning_rate</span><span class="cm-operator">*</span><span class="cm-variable">grads</span>[<span class="cm-string">'b'</span>]<span class="cm-operator">/</span>(<span class="cm-variable">np</span>.<span class="cm-property">sqrt</span>(<span class="cm-variable">G_b</span>) <span class="cm-operator">+</span> <span class="cm-variable">epsilon</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 181px;"></div><div class="CodeMirror-gutters" style="display: none; height: 181px;"></div></div></div></pre><p><strong><span>4. Adadelta</span></strong></p><p>&nbsp;</p><p><strong><span>5. RMSprop</span></strong></p><p><img src="image/1/1-1.7-5.png" referrerpolicy="no-referrer" alt="1568822196785"></p><p><span>原作者的公式中</span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.201ex" height="1.877ex" viewBox="0 -504.6 517 808.1" role="img" focusable="false" style="vertical-align: -0.705ex;"><defs><path stroke-width="0" id="E14-MJMATHI-3C1" d="M58 -216Q25 -216 23 -186Q23 -176 73 26T127 234Q143 289 182 341Q252 427 341 441Q343 441 349 441T359 442Q432 442 471 394T510 276Q510 219 486 165T425 74T345 13T266 -10H255H248Q197 -10 165 35L160 41L133 -71Q108 -168 104 -181T92 -202Q76 -216 58 -216ZM424 322Q424 359 407 382T357 405Q322 405 287 376T231 300Q217 269 193 170L176 102Q193 26 260 26Q298 26 334 62Q367 92 389 158T418 266T424 322Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E14-MJMATHI-3C1" x="0" y="0"></use></g></svg></span><script type="math/tex">\rho</script><span>写错，应为 </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.331ex" height="2.461ex" viewBox="0 -806.1 573 1059.4" role="img" focusable="false" style="vertical-align: -0.588ex;"><defs><path stroke-width="0" id="E15-MJMATHI-3B2" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E15-MJMATHI-3B2" x="0" y="0"></use></g></svg></span><script type="math/tex">\beta</script></p><p><strong><span>6.  Adam</span></strong></p><p><span>动量的vdW，RMSprop的sdW带了偏差修正，两者结合</span></p><p><img src="image/1/1-1.7-6.png" referrerpolicy="no-referrer" alt="img"></p><p>&nbsp;</p><p><a href='https://www.cnblogs.com/guoyaohua/p/8542554.html' target='_blank' class='url'>https://www.cnblogs.com/guoyaohua/p/8542554.html</a></p><p><a href='https://blog.csdn.net/qq_38622495/article/details/82689885' target='_blank' class='url'>https://blog.csdn.net/qq_38622495/article/details/82689885</a></p><p><a href='http://zh.gluon.ai/chapter_optimization/momentum.html' target='_blank' class='url'>http://zh.gluon.ai/chapter_optimization/momentum.html</a></p><p><a href='#目录'><span>回到顶部</span></a></p><h3><a name="18-几种学习率衰减方法" class="md-header-anchor"></a><span>1.8 几种学习率衰减方法</span></h3><p><a href='https://blog.csdn.net/fzp95/article/details/85008413' target='_blank' class='url'>https://blog.csdn.net/fzp95/article/details/85008413</a></p><p><a href='https://blog.csdn.net/zxyhhjs2017/article/details/82383723' target='_blank' class='url'>https://blog.csdn.net/zxyhhjs2017/article/details/82383723</a></p><ol start='' ><li><p><strong><span>指数衰减</span></strong><span> exponential_decay</span></p><p><code>decay_rate</code><span>越</span><strong><span>小</span></strong><span>，下降越快</span></p></li></ol><pre spellcheck="false" class="md-fences md-end-block ty-contain-cm modeLoaded" lang=""><div class="CodeMirror cm-s-inner CodeMirror-wrap" lang=""><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">decayed_learning_rate = learning_rate *</span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  decay_rate ^ (global_step / decay_steps)</span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 68px;"></div><div class="CodeMirror-gutters" style="display: none; height: 68px;"></div></div></div></pre><ol start='2' ><li><p><strong><span>自然指数衰减</span></strong><span> exponential_time_decay</span></p><p><code>decay_rate</code><span>越</span><strong><span>大</span></strong><span>，下降越快</span></p></li></ol><pre spellcheck="false" class="md-fences md-end-block ty-contain-cm modeLoaded" lang=""><div class="CodeMirror cm-s-inner CodeMirror-wrap" lang=""><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">decayed_learning_rate = learning_rate * exp(-decay_rate * global_step)</span></pre></div></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 45px;"></div><div class="CodeMirror-gutters" style="display: none; height: 45px;"></div></div></div></pre><ol start='3' ><li><p><strong><span>多项式衰减</span></strong><span> polynomial_decay</span></p><p><code>learning_rate</code><span>在</span><code>decay_steps</code><span>步内，到达</span><code>end_learning_rate</code><span>。</span><code>power</code><span>为1时是一阶下降，可以cycle</span></p></li></ol><pre spellcheck="false" class="md-fences md-end-block ty-contain-cm modeLoaded" lang=""><div class="CodeMirror cm-s-inner CodeMirror-wrap" lang=""><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">decayed_learning_rate = (learning_rate - end_learning_rate) *</span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (1 - global_step / decay_steps) ^ (power) +end_learning_rate</span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 91px;"></div><div class="CodeMirror-gutters" style="display: none; height: 91px;"></div></div></div></pre><ol start='4' ><li><strong><span>余弦衰减</span></strong><span> cosine_decay</span></li></ol><p><span>等等</span></p><p><a href='#目录'><span>回到顶部</span></a></p><h3><a name="19-几种参数初始化方法" class="md-header-anchor"></a><span>1.9 几种参数初始化方法</span></h3><ol start='' ><li><strong><span>标准初始化</span></strong><span> 高斯初始化</span></li></ol><p><span>标准正态分布和截断正态分布 保证固定的均值和标准差</span></p><p><span>截断正态分布(Truncated_normal)保证值在（μ-2σ，μ+2σ）之间</span></p><ol start='2' ><li><span>Xavier初始化</span></li></ol><p>&nbsp;</p><ol start='3' ><li><span>He初始化</span></li></ol><p>&nbsp;</p><p><a href='https://mp.weixin.qq.com/s/rHCl3fT7FS-TF1-WafjL3Q' target='_blank' class='url'>https://mp.weixin.qq.com/s/rHCl3fT7FS-TF1-WafjL3Q</a></p><p><a href='#目录'><span>回到顶部</span></a></p><h3><a name="110-几种损失函数" class="md-header-anchor"></a><span>1.10 几种损失函数</span></h3><p><strong><span>1. log对数损失函数（逻辑回归）</span></strong></p><p><span>逻辑回归的推导中，它假设样本服从伯努利分布（0-1分布），然后求得满足该分布的似然函数，接着取对数求极值</span></p><div contenteditable="false" spellcheck="false" class="mathjax-block md-end-block md-math-block md-rawblock" id="mathjax-n188" cid="n188" mdtype="math_block"><div class="md-rawblock-container md-math-container" tabindex="-1"><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-2-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="30.736ex" height="2.577ex" viewBox="0 -806.1 13233.6 1109.7" role="img" focusable="false" style="vertical-align: -0.705ex; max-width: 100%;"><defs><path stroke-width="0" id="E28-MJMATHI-4C" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path><path stroke-width="0" id="E28-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path stroke-width="0" id="E28-MJMATHI-59" d="M66 637Q54 637 49 637T39 638T32 641T30 647T33 664T42 682Q44 683 56 683Q104 680 165 680Q288 680 306 683H316Q322 677 322 674T320 656Q316 643 310 637H298Q242 637 242 624Q242 619 292 477T343 333L346 336Q350 340 358 349T379 373T411 410T454 461Q546 568 561 587T577 618Q577 634 545 637Q528 637 528 647Q528 649 530 661Q533 676 535 679T549 683Q551 683 578 682T657 680Q684 680 713 681T746 682Q763 682 763 673Q763 669 760 657T755 643Q753 637 734 637Q662 632 617 587Q608 578 477 424L348 273L322 169Q295 62 295 57Q295 46 363 46Q379 46 384 45T390 35Q390 33 388 23Q384 6 382 4T366 1Q361 1 324 1T232 2Q170 2 138 2T102 1Q84 1 84 9Q84 14 87 24Q88 27 89 30T90 35T91 39T93 42T96 44T101 45T107 45T116 46T129 46Q168 47 180 50T198 63Q201 68 227 171L252 274L129 623Q128 624 127 625T125 627T122 629T118 631T113 633T105 634T96 635T83 636T66 637Z"></path><path stroke-width="0" id="E28-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path stroke-width="0" id="E28-MJMATHI-50" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path><path stroke-width="0" id="E28-MJMAIN-7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path><path stroke-width="0" id="E28-MJMATHI-58" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path><path stroke-width="0" id="E28-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path stroke-width="0" id="E28-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path stroke-width="0" id="E28-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path stroke-width="0" id="E28-MJMAIN-6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path><path stroke-width="0" id="E28-MJMAIN-6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z"></path><path stroke-width="0" id="E28-MJMAIN-67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E28-MJMATHI-4C" x="0" y="0"></use><use xlink:href="#E28-MJMAIN-28" x="681" y="0"></use><use xlink:href="#E28-MJMATHI-59" x="1070" y="0"></use><use xlink:href="#E28-MJMAIN-2C" x="1833" y="0"></use><use xlink:href="#E28-MJMATHI-50" x="2277" y="0"></use><use xlink:href="#E28-MJMAIN-28" x="3028" y="0"></use><use xlink:href="#E28-MJMATHI-59" x="3417" y="0"></use><use xlink:href="#E28-MJMAIN-7C" x="4180" y="0"></use><use xlink:href="#E28-MJMATHI-58" x="4458" y="0"></use><use xlink:href="#E28-MJMAIN-29" x="5310" y="0"></use><use xlink:href="#E28-MJMAIN-29" x="5699" y="0"></use><use xlink:href="#E28-MJMAIN-3D" x="6366" y="0"></use><use xlink:href="#E28-MJMAIN-2212" x="7422" y="0"></use><g transform="translate(8366,0)"><use xlink:href="#E28-MJMAIN-6C"></use><use xlink:href="#E28-MJMAIN-6F" x="278" y="0"></use><use xlink:href="#E28-MJMAIN-67" x="778" y="0"></use></g><use xlink:href="#E28-MJMATHI-50" x="9811" y="0"></use><use xlink:href="#E28-MJMAIN-28" x="10562" y="0"></use><use xlink:href="#E28-MJMATHI-59" x="10951" y="0"></use><use xlink:href="#E28-MJMAIN-7C" x="11714" y="0"></use><use xlink:href="#E28-MJMATHI-58" x="11992" y="0"></use><use xlink:href="#E28-MJMAIN-29" x="12844" y="0"></use></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-2">L(Y,P(Y|X)) = -\log P(Y|X)</script></div></div><p><span>损失函数L(Y, P(Y|X))表达的是样本X在分类Y的情况下，使概率P(Y|X)达到最大值（换言之，</span><strong><span>就是利用已知的样本分布，找到最有可能（即最大概率）导致这种分布的参数值；或者说什么样的参数才能使我们观测到目前这组数据的概率最大</span></strong><span>）</span></p><p><strong><span>2. Hinge 损失函数（SVM）</span></strong></p><div contenteditable="false" spellcheck="false" class="mathjax-block md-end-block md-math-block md-rawblock" id="mathjax-n191" cid="n191" mdtype="math_block"><div class="md-rawblock-container md-math-container" tabindex="-1"><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-3-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="30.672ex" height="2.577ex" viewBox="0 -806.1 13206.1 1109.7" role="img" focusable="false" style="vertical-align: -0.705ex; max-width: 100%;"><defs><path stroke-width="0" id="E29-MJMATHI-4C" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path><path stroke-width="0" id="E29-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path stroke-width="0" id="E29-MJMATHI-79" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E29-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path stroke-width="0" id="E29-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path stroke-width="0" id="E29-MJMAIN-6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path stroke-width="0" id="E29-MJMAIN-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path><path stroke-width="0" id="E29-MJMAIN-78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z"></path><path stroke-width="0" id="E29-MJMAIN-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path stroke-width="0" id="E29-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path stroke-width="0" id="E29-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path stroke-width="0" id="E29-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path stroke-width="0" id="E29-MJMAIN-7E" d="M179 251Q164 251 151 245T131 234T111 215L97 227L83 238Q83 239 95 253T121 283T142 304Q165 318 187 318T253 300T320 282Q335 282 348 288T368 299T388 318L402 306L416 295Q375 236 344 222Q330 215 313 215Q292 215 248 233T179 251Z"></path><path stroke-width="0" id="E29-MJMAIN-B1" d="M56 320T56 333T70 353H369V502Q369 651 371 655Q376 666 388 666Q402 666 405 654T409 596V500V353H707Q722 345 722 333Q722 320 707 313H409V40H707Q722 32 722 20T707 0H70Q56 7 56 20T70 40H369V313H70Q56 320 56 333Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E29-MJMATHI-4C" x="0" y="0"></use><use xlink:href="#E29-MJMAIN-28" x="681" y="0"></use><use xlink:href="#E29-MJMATHI-79" x="1070" y="0"></use><use xlink:href="#E29-MJMAIN-29" x="1567" y="0"></use><use xlink:href="#E29-MJMAIN-3D" x="2233" y="0"></use><g transform="translate(3289,0)"><use xlink:href="#E29-MJMAIN-6D"></use><use xlink:href="#E29-MJMAIN-61" x="833" y="0"></use><use xlink:href="#E29-MJMAIN-78" x="1333" y="0"></use></g><use xlink:href="#E29-MJMAIN-28" x="5150" y="0"></use><use xlink:href="#E29-MJMAIN-30" x="5539" y="0"></use><use xlink:href="#E29-MJMAIN-2C" x="6039" y="0"></use><use xlink:href="#E29-MJMAIN-31" x="6484" y="0"></use><use xlink:href="#E29-MJMAIN-2212" x="7206" y="0"></use><use xlink:href="#E29-MJMATHI-79" x="8206" y="0"></use><g transform="translate(8703,0)"><use xlink:href="#E29-MJMATHI-79" x="1" y="0"></use><use xlink:href="#E29-MJMAIN-7E" x="60" y="303"></use></g><use xlink:href="#E29-MJMAIN-29" x="9263" y="0"></use><use xlink:href="#E29-MJMAIN-2C" x="9652" y="0"></use><use xlink:href="#E29-MJMATHI-79" x="10097" y="0"></use><use xlink:href="#E29-MJMAIN-3D" x="10872" y="0"></use><use xlink:href="#E29-MJMAIN-B1" x="11928" y="0"></use><use xlink:href="#E29-MJMAIN-31" x="12706" y="0"></use></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-3">L(y) = \max(0, 1-y\tilde{y}), y=\pm 1</script></div></div><p><strong><span>3. Huber loss（smooth L1）</span></strong></p><p><span>相比于最小二乘的线性回归，HuberLoss降低了对离群点的惩罚程度</span></p><div contenteditable="false" spellcheck="false" class="mathjax-block md-end-block md-math-block md-rawblock" id="mathjax-n194" cid="n194" mdtype="math_block"><div class="md-rawblock-container md-math-container" tabindex="-1"><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-4-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="38.28ex" height="7.247ex" viewBox="0 -1811.3 16481.6 3120.1" role="img" focusable="false" style="vertical-align: -3.04ex; max-width: 100%;"><defs><path stroke-width="0" id="E30-MJMATHI-4C" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path><path stroke-width="0" id="E30-MJMATHI-3B4" d="M195 609Q195 656 227 686T302 717Q319 716 351 709T407 697T433 690Q451 682 451 662Q451 644 438 628T403 612Q382 612 348 641T288 671T249 657T235 628Q235 584 334 463Q401 379 401 292Q401 169 340 80T205 -10H198Q127 -10 83 36T36 153Q36 286 151 382Q191 413 252 434Q252 435 245 449T230 481T214 521T201 566T195 609ZM112 130Q112 83 136 55T204 27Q233 27 256 51T291 111T309 178T316 232Q316 267 309 298T295 344T269 400L259 396Q215 381 183 342T137 256T118 179T112 130Z"></path><path stroke-width="0" id="E30-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path stroke-width="0" id="E30-MJMATHI-61" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path><path stroke-width="0" id="E30-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path stroke-width="0" id="E30-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path stroke-width="0" id="E30-MJMAIN-7B" d="M434 -231Q434 -244 428 -250H410Q281 -250 230 -184Q225 -177 222 -172T217 -161T213 -148T211 -133T210 -111T209 -84T209 -47T209 0Q209 21 209 53Q208 142 204 153Q203 154 203 155Q189 191 153 211T82 231Q71 231 68 234T65 250T68 266T82 269Q116 269 152 289T203 345Q208 356 208 377T209 529V579Q209 634 215 656T244 698Q270 724 324 740Q361 748 377 749Q379 749 390 749T408 750H428Q434 744 434 732Q434 719 431 716Q429 713 415 713Q362 710 332 689T296 647Q291 634 291 499V417Q291 370 288 353T271 314Q240 271 184 255L170 250L184 245Q202 239 220 230T262 196T290 137Q291 131 291 1Q291 -134 296 -147Q306 -174 339 -192T415 -213Q429 -213 431 -216Q434 -219 434 -231Z"></path><path stroke-width="0" id="E30-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path stroke-width="0" id="E30-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path stroke-width="0" id="E30-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path><path stroke-width="0" id="E30-MJMAIN-66" d="M273 0Q255 3 146 3Q43 3 34 0H26V46H42Q70 46 91 49Q99 52 103 60Q104 62 104 224V385H33V431H104V497L105 564L107 574Q126 639 171 668T266 704Q267 704 275 704T289 705Q330 702 351 679T372 627Q372 604 358 590T321 576T284 590T270 627Q270 647 288 667H284Q280 668 273 668Q245 668 223 647T189 592Q183 572 182 497V431H293V385H185V225Q185 63 186 61T189 57T194 54T199 51T206 49T213 48T222 47T231 47T241 46T251 46H282V0H273Z"></path><path stroke-width="0" id="E30-MJMAIN-6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z"></path><path stroke-width="0" id="E30-MJMAIN-72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z"></path><path stroke-width="0" id="E30-MJMAIN-7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path><path stroke-width="0" id="E30-MJMAIN-2264" d="M674 636Q682 636 688 630T694 615T687 601Q686 600 417 472L151 346L399 228Q687 92 691 87Q694 81 694 76Q694 58 676 56H670L382 192Q92 329 90 331Q83 336 83 348Q84 359 96 365Q104 369 382 500T665 634Q669 636 674 636ZM84 -118Q84 -108 99 -98H678Q694 -104 694 -118Q694 -130 679 -138H98Q84 -131 84 -118Z"></path><path stroke-width="0" id="E30-MJMAIN-22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path><path stroke-width="0" id="E30-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path stroke-width="0" id="E30-MJMAIN-74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path><path stroke-width="0" id="E30-MJMAIN-68" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 124T102 167T103 217T103 272T103 329Q103 366 103 407T103 482T102 542T102 586T102 603Q99 622 88 628T43 637H25V660Q25 683 27 683L37 684Q47 685 66 686T103 688Q120 689 140 690T170 693T181 694H184V367Q244 442 328 442Q451 442 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path><path stroke-width="0" id="E30-MJMAIN-65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z"></path><path stroke-width="0" id="E30-MJMAIN-77" d="M90 368Q84 378 76 380T40 385H18V431H24L43 430Q62 430 84 429T116 428Q206 428 221 431H229V385H215Q177 383 177 368Q177 367 221 239L265 113L339 328L333 345Q323 374 316 379Q308 384 278 385H258V431H264Q270 428 348 428Q439 428 454 431H461V385H452Q404 385 404 369Q404 366 418 324T449 234T481 143L496 100L537 219Q579 341 579 347Q579 363 564 373T530 385H522V431H529Q541 428 624 428Q692 428 698 431H703V385H697Q696 385 691 385T682 384Q635 377 619 334L559 161Q546 124 528 71Q508 12 503 1T487 -11H479Q460 -11 456 -4Q455 -3 407 133L361 267Q359 263 266 -4Q261 -11 243 -11H238Q225 -11 220 -3L90 368Z"></path><path stroke-width="0" id="E30-MJMAIN-69" d="M69 609Q69 637 87 653T131 669Q154 667 171 652T188 609Q188 579 171 564T129 549Q104 549 87 564T69 609ZM247 0Q232 3 143 3Q132 3 106 3T56 1L34 0H26V46H42Q70 46 91 49Q100 53 102 60T104 102V205V293Q104 345 102 359T88 378Q74 385 41 385H30V408Q30 431 32 431L42 432Q52 433 70 434T106 436Q123 437 142 438T171 441T182 442H185V62Q190 52 197 50T232 46H255V0H247Z"></path><path stroke-width="0" id="E30-MJMAIN-73" d="M295 316Q295 356 268 385T190 414Q154 414 128 401Q98 382 98 349Q97 344 98 336T114 312T157 287Q175 282 201 278T245 269T277 256Q294 248 310 236T342 195T359 133Q359 71 321 31T198 -10H190Q138 -10 94 26L86 19L77 10Q71 4 65 -1L54 -11H46H42Q39 -11 33 -5V74V132Q33 153 35 157T45 162H54Q66 162 70 158T75 146T82 119T101 77Q136 26 198 26Q295 26 295 104Q295 133 277 151Q257 175 194 187T111 210Q75 227 54 256T33 318Q33 357 50 384T93 424T143 442T187 447H198Q238 447 268 432L283 424L292 431Q302 440 314 448H322H326Q329 448 335 442V310L329 304H301Q295 310 295 316Z"></path><path stroke-width="0" id="E30-MJMAIN-2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path><path stroke-width="0" id="E30-MJSZ4-7B" d="M661 -1243L655 -1249H622L604 -1240Q503 -1190 434 -1107T348 -909Q346 -897 346 -499L345 -98L343 -82Q335 3 287 87T157 223Q146 232 145 236Q144 240 144 250Q144 265 145 268T157 278Q242 333 288 417T343 583L345 600L346 1001Q346 1398 348 1410Q379 1622 600 1739L622 1750H655L661 1744V1727V1721Q661 1712 661 1710T657 1705T648 1700T630 1690T602 1668Q589 1659 574 1643T531 1593T484 1508T459 1398Q458 1389 458 1001Q458 614 457 605Q441 435 301 316Q254 277 202 251L250 222Q260 216 301 185Q443 66 457 -104Q458 -113 458 -501Q458 -888 459 -897Q463 -944 478 -988T509 -1060T548 -1114T580 -1149T602 -1167Q620 -1183 634 -1192T653 -1202T659 -1207T661 -1220V-1226V-1243Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><g transform="translate(167,0)"><g transform="translate(-15,0)"><use xlink:href="#E30-MJMATHI-4C" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E30-MJMATHI-3B4" x="963" y="-230"></use><use xlink:href="#E30-MJMAIN-28" x="1099" y="0"></use><use xlink:href="#E30-MJMATHI-61" x="1488" y="0"></use><use xlink:href="#E30-MJMAIN-29" x="2017" y="0"></use><use xlink:href="#E30-MJMAIN-3D" x="2684" y="0"></use><g transform="translate(3740,0)"><use xlink:href="#E30-MJSZ4-7B"></use><g transform="translate(973,0)"><g transform="translate(-15,0)"><g transform="translate(0,825)"><g transform="translate(120,0)"><rect stroke="none" width="473" height="60" x="0" y="220"></rect><use transform="scale(0.707)" xlink:href="#E30-MJMAIN-31" x="84" y="571"></use><use transform="scale(0.707)" xlink:href="#E30-MJMAIN-32" x="84" y="-531"></use></g><g transform="translate(713,0)"><use xlink:href="#E30-MJMATHI-61" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E30-MJMAIN-32" x="748" y="513"></use></g><use xlink:href="#E30-MJMAIN-2C" x="1696" y="0"></use></g><g transform="translate(0,-826)"><use xlink:href="#E30-MJMATHI-3B4" x="0" y="0"></use><use xlink:href="#E30-MJMAIN-22C5" x="673" y="0"></use><use xlink:href="#E30-MJMAIN-28" x="1173" y="0"></use><use xlink:href="#E30-MJMAIN-7C" x="1562" y="0"></use><use xlink:href="#E30-MJMATHI-61" x="1840" y="0"></use><use xlink:href="#E30-MJMAIN-7C" x="2369" y="0"></use><use xlink:href="#E30-MJMAIN-2212" x="2869" y="0"></use><g transform="translate(3647,0)"><g transform="translate(342,0)"><rect stroke="none" width="473" height="60" x="0" y="220"></rect><use transform="scale(0.707)" xlink:href="#E30-MJMAIN-31" x="84" y="571"></use><use transform="scale(0.707)" xlink:href="#E30-MJMAIN-32" x="84" y="-531"></use></g></g><use xlink:href="#E30-MJMATHI-3B4" x="4583" y="0"></use><use xlink:href="#E30-MJMAIN-29" x="5034" y="0"></use><use xlink:href="#E30-MJMAIN-2C" x="5423" y="0"></use></g></g><g transform="translate(6686,0)"><g transform="translate(0,825)"><use xlink:href="#E30-MJMAIN-66"></use><use xlink:href="#E30-MJMAIN-6F" x="306" y="0"></use><use xlink:href="#E30-MJMAIN-72" x="806" y="0"></use><use xlink:href="#E30-MJMAIN-7C" x="1448" y="0"></use><use xlink:href="#E30-MJMATHI-61" x="1726" y="0"></use><use xlink:href="#E30-MJMAIN-7C" x="2255" y="0"></use><use xlink:href="#E30-MJMAIN-2264" x="2810" y="0"></use><use xlink:href="#E30-MJMATHI-3B4" x="3866" y="0"></use><use xlink:href="#E30-MJMAIN-2C" x="4317" y="0"></use></g><g transform="translate(0,-826)"><use xlink:href="#E30-MJMAIN-6F"></use><use xlink:href="#E30-MJMAIN-74" x="500" y="0"></use><use xlink:href="#E30-MJMAIN-68" x="889" y="0"></use><use xlink:href="#E30-MJMAIN-65" x="1445" y="0"></use><use xlink:href="#E30-MJMAIN-72" x="1889" y="0"></use><use xlink:href="#E30-MJMAIN-77" x="2281" y="0"></use><use xlink:href="#E30-MJMAIN-69" x="3003" y="0"></use><use xlink:href="#E30-MJMAIN-73" x="3281" y="0"></use><use xlink:href="#E30-MJMAIN-65" x="3675" y="0"></use><use xlink:href="#E30-MJMAIN-2E" x="4119" y="0"></use></g></g></g></g></g></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-4">\begin{split}
L_\delta(a)=\left \{
\begin{array}{ll}
\frac12a^2,&\textrm{for } |a|\leq\delta,\\
\delta\cdot(|a|-\frac12\delta),&\textrm{otherwise.}
\end{array}
\right.
\end{split}</script></div></div><p><span>当预测偏差小于 δ 时，它采用平方误差，当预测偏差大于 δ 时，采用的线性误差。当δ为1时，就是smooth L1 loss</span></p><p>&nbsp;</p><p><a href='#目录'><span>回到顶部</span></a></p><h3><a name="111-为什么需要非线性激活函数" class="md-header-anchor"></a><span>1.11 为什么需要非线性激活函数？</span></h3><p><strong><span>为什么需要激活函数？</span></strong></p><ol start='' ><li><span>激活函数可以引入</span><strong><span>非线性因素</span></strong><span>。如果不使用激活函数，则输出信号仅是一个简单的线性函数。线性函数一个一级多项式，线性方程的复杂度有限，从数据中学习复杂函数映射的能力很小。没有激活函数，神经网络将无法学习和模拟其他复杂类型的数据，例如图像、视频、音频、语音等。</span></li><li><span>激活函数可以把当前特征空间通过一定的线性映射转换到另一个空间，让数据能够更好的被分类。</span></li></ol><p><strong><span>为什么激活函数需要非线性函数？</span></strong></p><ol start='' ><li><span>假若网络中全部是线性部件，那么线性的组合还是线性，与单独一个线性分类器无异。这样就做不到用非线性来逼近任意函数。</span></li><li><span>使用非线性激活函数 ，以便使网络更加强大，增加它的能力，使它可以学习复杂的事物，复杂的表单数据，以及表示输入输出之间非线性的复杂的任意函数映射。使用非线性激活函数，能够从输入输出之间生成非线性映射。</span></li></ol><p><strong><span>激活函数有哪些性质？</span></strong></p><ol start='' ><li><span>非线性： 当激活函数是线性的，一个两层的神经网络就可以基本上逼近所有的函数。但如果激活函数是恒等激活函数的时候，即 </span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="8.839ex" height="2.577ex" viewBox="0 -806.1 3805.6 1109.7" role="img" focusable="false" style="vertical-align: -0.705ex;"><defs><path stroke-width="0" id="E16-MJMATHI-66" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path><path stroke-width="0" id="E16-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path stroke-width="0" id="E16-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path stroke-width="0" id="E16-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path stroke-width="0" id="E16-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E16-MJMATHI-66" x="0" y="0"></use><use xlink:href="#E16-MJMAIN-28" x="550" y="0"></use><use xlink:href="#E16-MJMATHI-78" x="939" y="0"></use><use xlink:href="#E16-MJMAIN-29" x="1511" y="0"></use><use xlink:href="#E16-MJMAIN-3D" x="2177" y="0"></use><use xlink:href="#E16-MJMATHI-78" x="3233" y="0"></use></g></svg></span><script type="math/tex"> f(x)=x </script><span>，就不满足这个性质，而且如果 MLP 使用的是恒等激活函数，那么其实整个网络跟单层神经网络是等价的；</span></li><li><span>可微性： 当优化方法是基于梯度的时候，就体现了该性质；</span></li><li><span>单调性： 当激活函数是单调的时候，单层网络能够保证是凸函数；</span></li><li><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="8.839ex" height="2.577ex" viewBox="0 -806.1 3805.6 1109.7" role="img" focusable="false" style="vertical-align: -0.705ex;"><defs><path stroke-width="0" id="E17-MJMATHI-66" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path><path stroke-width="0" id="E17-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path stroke-width="0" id="E17-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path><path stroke-width="0" id="E17-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path stroke-width="0" id="E17-MJMAIN-2248" d="M55 319Q55 360 72 393T114 444T163 472T205 482Q207 482 213 482T223 483Q262 483 296 468T393 413L443 381Q502 346 553 346Q609 346 649 375T694 454Q694 465 698 474T708 483Q722 483 722 452Q722 386 675 338T555 289Q514 289 468 310T388 357T308 404T224 426Q164 426 125 393T83 318Q81 289 69 289Q55 289 55 319ZM55 85Q55 126 72 159T114 210T163 238T205 248Q207 248 213 248T223 249Q262 249 296 234T393 179L443 147Q502 112 553 112Q609 112 649 141T694 220Q694 249 708 249T722 217Q722 153 675 104T555 55Q514 55 468 76T388 123T308 170T224 192Q164 192 125 159T83 84Q80 55 69 55Q55 55 55 85Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E17-MJMATHI-66" x="0" y="0"></use><use xlink:href="#E17-MJMAIN-28" x="550" y="0"></use><use xlink:href="#E17-MJMATHI-78" x="939" y="0"></use><use xlink:href="#E17-MJMAIN-29" x="1511" y="0"></use><use xlink:href="#E17-MJMAIN-2248" x="2177" y="0"></use><use xlink:href="#E17-MJMATHI-78" x="3233" y="0"></use></g></svg></span><script type="math/tex"> f(x)≈x </script><span>： 当激活函数满足这个性质的时候，如果参数的初始化是随机的较小值，那么神经网络的训练将会很高效；如果不满足这个性质，那么就需要详细地去设置初始值；</span></li><li><span>输出值的范围： 当激活函数输出值是有限的时候，基于梯度的优化方法会更加稳定，因为特征的表示受有限权值的影响更显著；当激活函数的输出是无限的时候，模型的训练会更加高效，不过在这种情况小，一般需要更小的 Learning Rate。</span></li></ol><p><a href='#目录'><span>回到顶部</span></a></p><h3><a name="111-几种激活函数及其导数" class="md-header-anchor"></a><span>1.11 几种激活函数及其导数</span></h3><p><span>对常见激活函数，导数计算如下：</span></p><p><img src="image/1/1-1.11.png" referrerpolicy="no-referrer"></p><h3><a name="112-指定训练用gpu" class="md-header-anchor"></a><span>1.12 指定训练用GPU</span></h3><p><span>两种方法</span></p><ol start='' ><li><p><span>终端指定：</span></p><p><code>CUDA_VISIBLE_DEVICES=0 python train.py</code><span> 或 </span><code>export CUDA_VISIBLE_DEVICES=1</code></p></li><li><p><span>代码中指定：</span></p><pre spellcheck="false" class="md-fences md-end-block ty-contain-cm modeLoaded" lang="python"><div class="CodeMirror cm-s-inner CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">os</span></span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">os</span>.<span class="cm-property">environ</span>[<span class="cm-string">"CUDA_VISIBLE_DEVICES"</span>] = <span class="cm-string">"1"</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 45px;"></div><div class="CodeMirror-gutters" style="display: none; height: 45px;"></div></div></div></pre><pre spellcheck="false" class="md-fences md-end-block ty-contain-cm modeLoaded" lang="python"><div class="CodeMirror cm-s-inner CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation" style=""><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">c</span> = []</span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">for</span> <span class="cm-variable">d</span> <span class="cm-keyword">in</span> [<span class="cm-string">'/gpu:0'</span>, <span class="cm-string">'/gpu:1'</span>]:</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;<span class="cm-keyword cm-error">with</span> <span class="cm-variable">tf</span>.<span class="cm-property">device</span>(<span class="cm-variable">d</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">a</span> = <span class="cm-variable">tf</span>.<span class="cm-property">constant</span>([<span class="cm-number">1.0</span>, <span class="cm-number">2.0</span>, <span class="cm-number">3.0</span>, <span class="cm-number">4.0</span>, <span class="cm-number">5.0</span>, <span class="cm-number">6.0</span>], <span class="cm-variable">shape</span>=[<span class="cm-number">2</span>, <span class="cm-number">3</span>])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">b</span> = <span class="cm-variable">tf</span>.<span class="cm-property">constant</span>([<span class="cm-number">1.0</span>, <span class="cm-number">2.0</span>, <span class="cm-number">3.0</span>, <span class="cm-number">4.0</span>, <span class="cm-number">5.0</span>, <span class="cm-number">6.0</span>], <span class="cm-variable">shape</span>=[<span class="cm-number">3</span>, <span class="cm-number">2</span>])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">c</span>.<span class="cm-property">append</span>(<span class="cm-variable">tf</span>.<span class="cm-property">matmul</span>(<span class="cm-variable">a</span>, <span class="cm-variable">b</span>))</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">with</span> <span class="cm-variable">tf</span>.<span class="cm-property">device</span>(<span class="cm-string">'/cpu:0'</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp;<span class="cm-builtin cm-error">sum</span> = <span class="cm-variable">tf</span>.<span class="cm-property">add_n</span>(<span class="cm-variable">c</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># Creates a session with log_device_placement set to True.</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">sess</span> = <span class="cm-variable">tf</span>.<span class="cm-property">Session</span>(<span class="cm-variable">config</span>=<span class="cm-variable">tf</span>.<span class="cm-property">ConfigProto</span>(<span class="cm-variable">log_device_placement</span>=<span class="cm-keyword">True</span>))</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># Runs the op.</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-builtin">print</span> <span class="cm-variable">sess</span>.<span class="cm-property">run</span>(<span class="cm-builtin">sum</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 385px;"></div><div class="CodeMirror-gutters" style="display: none; height: 385px;"></div></div></div></pre></li></ol><p><a href='https://blog.csdn.net/sinat_30372583/article/details/79857628' target='_blank' class='url'>https://blog.csdn.net/sinat_30372583/article/details/79857628</a></p><p><a href='#目录'><span>回到顶部</span></a></p><h3><a name="113-maxpooling-怎么反向传播" class="md-header-anchor"></a><span>1.13 maxpooling 怎么反向传播</span></h3><p><span>CNN中一些特殊环节的反向传播：</span><a href='https://blog.csdn.net/qq_21190081/article/details/72871704' target='_blank' class='url'>https://blog.csdn.net/qq_21190081/article/details/72871704</a></p><p><span>max pooling和mean pooling不同，max pooling需要记录下最大值的id，反向传播时传给这个id</span></p><p><a href='https://blog.csdn.net/Jason_yyz/article/details/80003271' target='_blank' class='url'>https://blog.csdn.net/Jason_yyz/article/details/80003271</a></p><h3><a name="114-梯度消失和梯度爆炸的原因和解决" class="md-header-anchor"></a><span>1.14 梯度消失和梯度爆炸的原因和解决</span></h3><p><strong><span>梯度消失：</span></strong></p><ol start='' ><li><span>不合适的激活函数 ---&gt; relu</span></li><li><span>网络太深 ---&gt; 残差模块</span></li><li><span>数据分布没有归一化  ---&gt; BN</span></li></ol><p><strong><span>梯度爆炸：</span></strong></p><p><span>梯度在网络更新的过程中不断累积，变成非常大的梯度，导致网络权重值的大幅更新，使得网络不稳定；在极端情况下，权重值甚至会溢出，变为NaN值，再也无法更新</span></p><h3><a name="115-感受野计算" class="md-header-anchor"></a><span>1.15 感受野计算</span></h3><p><a href='https://blog.csdn.net/Kerrwy/article/details/82430530' target='_blank' class='url'>https://blog.csdn.net/Kerrwy/article/details/82430530</a></p><p><a href='#目录'><span>回到顶部</span></a></p><h3><a name="116-正负样本不均衡时的解决方案" class="md-header-anchor"></a><span>1.16 正负样本不均衡时的解决方案</span></h3><ol start='' ><li><span>重采样，采样主要包括上采样（oversampling，有的称为过采样）和下采样（undersampling，有的称为降采样）</span></li><li><span>数据合成，利用已有样本来生成更多的样本，这种方法在小数据场景下有很多成功案例。</span></li><li><span>除了采样和生成新数据等方法，还可以通过加权的方式来解决数据不平衡问题，即对不同类别分错的代价不同</span></li></ol><p><strong><span>上采样：</span></strong><span>通过将小众类样本复制多份，来得到多个不同数据集的方式，每个数据集训练一个模型。</span></p><p><strong><span>下采样：</span></strong><span>从大众类众剔除一些样本，或者只从大众类样本中选取部分样本。多次下采样（放回采样，产生多个相互独立的数据集），进而训练多个不同的分类器，通过组合多个分类器的结果进而得到最终的结果，这种方式称为EasyEnsemble。</span></p><p>&nbsp;</p><h3><a name="117--加速网络收敛" class="md-header-anchor"></a><span>1.17  加速网络收敛</span></h3><p><span>BN</span></p><p><span>优化器</span></p><p><span>大学习率</span></p><h3><a name="118-网络不收敛怎么办" class="md-header-anchor"></a><span>1.18 网络不收敛怎么办</span></h3><p><span>模型训练遇到瓶颈</span></p><p><span>这里的瓶颈一般包括：梯度消失、大量神经元失活、梯度爆炸和弥散、学习率过大或过小等。</span></p><p><span>梯度消失时，模型的loss难以下降，就像走在高原上，几乎任何地方都是高海拔，可以通过梯度的检验来验证模型当前所处的状态。有时梯度的更新和反向传播代码存在bug时，也会有这样的问题。</span></p><p><span>在使用Relu激活函数的时候，当每一个神经元的输入X为负时，会使得该神经元输出恒为0，导致失活，由于此时梯度为0，无法恢复。有一种解决方案是使用LeakyRelu，这时，Y轴的左边图线会有一个很小的正梯度，使得神经网络在一定时间后可以得到恢复。不过LeakyRelu并不常用，因为部分神经元失活并不影响结果，相反，这种输出为0还有很多积极的作用。因为Relu方程输入为负时，输出值为0，利用此特性可以很好地忽略掉卷积核输出负相关信息，同时保留相关信息。</span></p><p><img src="image/20190226-1.jpg" referrerpolicy="no-referrer" alt="img"></p><p><img src="image/20190226-2.jpg" referrerpolicy="no-referrer" alt="img"></p><p><span> 梯度爆炸和梯度弥散产生的根本原因是，根据链式法则，深度学习中的梯度在逐层累积。如1.1的n次方无穷大，0.9的n次方无穷小。网络中某些层过大的输出也会造成梯度爆炸，此时应该为该输出取一个上界，可用最大范数约束。 </span></p><p>&nbsp;</p><p><a href='#目录'><span>回到顶部</span></a></p><h2><a name="2-数据" class="md-header-anchor"></a><span>2. 数据</span></h2><h3><a name="21-数据扩增的方法" class="md-header-anchor"></a><span>2.1 数据扩增的方法</span></h3><p><span>随机裁剪</span></p><p><span>平移</span></p><p><span>翻转（水平 垂直）</span></p><p><span>旋转</span></p><p><span>缩放</span></p><p><span>颜色变换（明暗 对比度 饱和度）</span></p><p><a href='#目录'><span>回到顶部</span></a></p><h3><a name="22-怎么发现不好的数据" class="md-header-anchor"></a><span>2.2 怎么发现不好的数据？</span></h3><p><span>先扔到网络里训练，等损失平稳后，把batch size调为1，看那些样本损失大，对这些样本修改标签、再训练。</span></p><p><span>或者等网络训练平稳后，保存网络，然后测试一遍训练集上的数据，观看每个样本的预测结果。</span></p><h3><a name="23-什么样的数据集不适合用深度学习" class="md-header-anchor"></a><span>2.3 什么样的数据集不适合用深度学习?</span></h3><p><strong><span>数据集太小</span></strong><span>，数据样本不足时，深度学习相对其它机器学习算法，没有明显优势。</span>
<span>数据集</span><strong><span>没有局部相关特性</span></strong><span>，目前深度学习表现比较好的领域主要是图像／语音／自然语言处理等领域，这些领域的一个共性是局部相关性。图像中像素组成物体，语音信号中音位组合成单词，文本数据中单词组合成句子，这些特征元素的组合一旦被打乱，表示的含义同时也被改变。对于没有这样的局部相关性的数据集，不适于使用深度学习算法进行处理。举个例子：预测一个人的健康状况，相关的参数会有年龄、职业、收入、家庭状况等各种元素，将这些元素打乱，并不会影响相关的结果。</span></p><p><a href='#目录'><span>回到顶部</span></a></p><h3><a name="24-resize的方法" class="md-header-anchor"></a><span>2.4 resize的方法</span></h3><p><span>以cv2.resize()为例：</span></p><figure><table><thead><tr><th style='text-align:left;' ><span>interpolation 选项</span></th><th style='text-align:left;' ><span>所用的插值方法</span></th></tr></thead><tbody><tr><td style='text-align:left;' ><span>INTER_NEAREST</span></td><td style='text-align:left;' ><span>最近邻插值</span></td></tr><tr><td style='text-align:left;' ><span>INTER_LINEAR</span></td><td style='text-align:left;' ><span>双线性插值（默认设置）</span></td></tr><tr><td style='text-align:left;' ><span>INTER_AREA</span></td><td style='text-align:left;' ><span>使用像素区域关系进行重采样。 它可能是图像抽取的首选方法，因为它会产生无云纹理的结果。 但是当图像缩放时，它类似于INTER_NEAREST方法。</span></td></tr><tr><td style='text-align:left;' ><span>INTER_CUBIC</span></td><td style='text-align:left;' ><span>4x4像素邻域的双三次插值</span></td></tr><tr><td style='text-align:left;' ><span>INTER_LANCZOS4</span></td><td style='text-align:left;' ><span>8x8像素邻域的Lanczos插值</span></td></tr></tbody></table></figure><p><a href='https://www.cnblogs.com/amarr/p/10565188.html' target='_blank' class='url'>https://www.cnblogs.com/amarr/p/10565188.html</a></p><p><a href='#目录'><span>回到顶部</span></a></p><h2><a name="3-代码" class="md-header-anchor"></a><span>3. 代码</span></h2><h3><a name="31-手写mnist分类" class="md-header-anchor"></a><span>3.1 手写MNIST分类</span></h3><p><strong><span>Keras:</span></strong></p><p><span>用到的几个模块：</span></p><p><span>keras.datasets:  mnist.load_data()</span></p><p><span>keras.models: Sequential()</span></p><p><span>keras.layers: Conv2D, Maxpooling2D, Dropout, Flatten, Dense </span></p><p><span>K.image_data_format()</span></p><p><span>keras.utils.to_categorical(x_train, num_classes)</span></p><pre spellcheck="false" class="md-fences md-end-block ty-contain-cm modeLoaded" lang="python" style="break-inside: unset;"><div class="CodeMirror cm-s-inner CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation" style=""><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">keras</span></span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">keras</span>.<span class="cm-property">datasets</span> <span class="cm-keyword">import</span> <span class="cm-variable">mnist</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">keras</span>.<span class="cm-property">models</span> <span class="cm-keyword">import</span> <span class="cm-variable">Sequential</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">keras</span>.<span class="cm-property">layers</span> <span class="cm-keyword">import</span> <span class="cm-variable">Conv2D</span>, <span class="cm-variable">MaxPooling2D</span>, <span class="cm-variable">Dense</span>, <span class="cm-variable">Dropout</span>, <span class="cm-variable">Flatten</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">keras</span> <span class="cm-keyword">import</span> <span class="cm-variable">backend</span> <span class="cm-keyword">as</span> <span class="cm-variable">K</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="">​</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">K</span>.<span class="cm-property">image_data_format</span>() == <span class="cm-string">'channels_first'</span>:</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="">​</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">batch_size</span> = <span class="cm-number">128</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">num_classes</span> = <span class="cm-number">10</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">epochs</span> = <span class="cm-number">12</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="">​</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment">#############</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment">#  准备数据  #</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment">#############</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">(<span class="cm-variable">x_train</span>, <span class="cm-variable">y_train</span>), (<span class="cm-variable">x_test</span>, <span class="cm-variable">y_test</span>) = <span class="cm-variable">mnist</span>.<span class="cm-property">load_data</span>()</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="">​</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># input image dimensions</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">img_rows</span>, <span class="cm-variable">img_cols</span> = <span class="cm-number">28</span>, <span class="cm-number">28</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="">​</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">x_train</span> = <span class="cm-variable">x_train</span>.<span class="cm-property">reshape</span>(<span class="cm-variable">x_train</span>.<span class="cm-property">shape</span>[<span class="cm-number">0</span>], <span class="cm-variable">img_rows</span>, <span class="cm-variable">img_cols</span>, <span class="cm-number">1</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">x_test</span> = <span class="cm-variable">x_test</span>.<span class="cm-property">reshape</span>(<span class="cm-variable">x_test</span>.<span class="cm-property">shape</span>[<span class="cm-number">0</span>], <span class="cm-variable">img_rows</span>, <span class="cm-variable">img_cols</span>, <span class="cm-number">1</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="">​</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">x_train</span> = <span class="cm-variable">x_train</span>.<span class="cm-property">astype</span>(<span class="cm-string">'float32'</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">x_test</span> = <span class="cm-variable">x_test</span>.<span class="cm-property">astype</span>(<span class="cm-string">'float32'</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">x_train</span> /= <span class="cm-number">255</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">x_test</span> /= <span class="cm-number">255</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-string">'x_train shape:'</span>, <span class="cm-variable">x_train</span>.<span class="cm-property">shape</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-variable">x_train</span>.<span class="cm-property">shape</span>[<span class="cm-number">0</span>], <span class="cm-string">'train samples'</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-variable">x_test</span>.<span class="cm-property">shape</span>[<span class="cm-number">0</span>], <span class="cm-string">'test samples'</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="">​</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># convert class vectors to binary class matrices</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">y_train</span> = <span class="cm-variable">keras</span>.<span class="cm-property">utils</span>.<span class="cm-property">to_categorical</span>(<span class="cm-variable">y_train</span>, <span class="cm-variable">num_classes</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">y_test</span> = <span class="cm-variable">keras</span>.<span class="cm-property">utils</span>.<span class="cm-property">to_categorical</span>(<span class="cm-variable">y_test</span>, <span class="cm-variable">num_classes</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="">​</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">input_shape</span> = (<span class="cm-variable">img_rows</span>, <span class="cm-variable">img_cols</span>, <span class="cm-number">1</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="">​</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">model</span> = <span class="cm-variable">Sequential</span>()</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">model</span>.<span class="cm-property">add</span>(<span class="cm-variable">Conv2D</span>(<span class="cm-number">32</span>, <span class="cm-variable">kernel_size</span>=(<span class="cm-number">3</span>, <span class="cm-number">3</span>),</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="cm-variable">activation</span>=<span class="cm-string">'relu'</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="cm-variable">input_shape</span>=<span class="cm-variable">input_shape</span>)) &nbsp;<span class="cm-comment"># 3x3卷积</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">model</span>.<span class="cm-property">add</span>(<span class="cm-variable">Conv2D</span>(<span class="cm-number">64</span>, (<span class="cm-number">3</span>, <span class="cm-number">3</span>), <span class="cm-variable">activation</span>=<span class="cm-string">'relu'</span>)) &nbsp;<span class="cm-comment"># 3x3卷积</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">model</span>.<span class="cm-property">add</span>(<span class="cm-variable">MaxPooling2D</span>(<span class="cm-variable">pool_size</span>=(<span class="cm-number">2</span>, <span class="cm-number">2</span>))) &nbsp;<span class="cm-comment"># 最大池化</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">model</span>.<span class="cm-property">add</span>(<span class="cm-variable">Dropout</span>(<span class="cm-number">0.25</span>)) &nbsp;<span class="cm-comment"># dropout在全连接之前添加</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">model</span>.<span class="cm-property">add</span>(<span class="cm-variable">Flatten</span>())</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">model</span>.<span class="cm-property">add</span>(<span class="cm-variable">Dense</span>(<span class="cm-number">128</span>, <span class="cm-variable">activation</span>=<span class="cm-string">'relu'</span>)) &nbsp;<span class="cm-comment"># 全连接</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">model</span>.<span class="cm-property">add</span>(<span class="cm-variable">Dropout</span>(<span class="cm-number">0.5</span>))</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">model</span>.<span class="cm-property">add</span>(<span class="cm-variable">Dense</span>(<span class="cm-variable">num_classes</span>, <span class="cm-variable">activation</span>=<span class="cm-string">'softmax'</span>)) &nbsp;<span class="cm-comment"># 全连接输出预测</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="">​</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">model</span>.<span class="cm-property">compile</span>(<span class="cm-variable">loss</span>=<span class="cm-variable">keras</span>.<span class="cm-property">losses</span>.<span class="cm-property">categorical_crossentropy</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">optimizer</span>=<span class="cm-variable">keras</span>.<span class="cm-property">optimizers</span>.<span class="cm-property">Adadelta</span>(),</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">metrics</span>=[<span class="cm-string">'accuracy'</span>])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">model</span>.<span class="cm-property">fit</span>(<span class="cm-variable">x_train</span>, <span class="cm-variable">y_train</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">batch_size</span>=<span class="cm-variable">batch_size</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">epochs</span>=<span class="cm-variable">epochs</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">verbose</span>=<span class="cm-number">1</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">validation_data</span>=(<span class="cm-variable">x_test</span>, <span class="cm-variable">y_test</span>)<span class="cm-variable">）</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 1496px;"></div><div class="CodeMirror-gutters" style="display: none; height: 1496px;"></div></div></div></pre><p><strong><span>Tensorflow:</span></strong></p><pre spellcheck="false" class="md-fences md-end-block ty-contain-cm modeLoaded" lang="python" style="break-inside: unset;"><div class="CodeMirror cm-s-inner CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation" style=""><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">tensorflow</span> <span class="cm-keyword">as</span> <span class="cm-variable">tf</span></span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">tensorflow</span>.<span class="cm-property">examples</span>.<span class="cm-property">tutorials</span>.<span class="cm-property">mnist</span> <span class="cm-keyword">import</span> <span class="cm-variable">input_data</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">from</span> <span class="cm-variable">tensorflow</span>.<span class="cm-property">examples</span>.<span class="cm-property">tutorials</span>.<span class="cm-property">mnist</span> <span class="cm-keyword">import</span> <span class="cm-variable">mnist</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">tensorflow</span>.<span class="cm-property">contrib</span>.<span class="cm-property">slim</span> <span class="cm-keyword">as</span> <span class="cm-variable">slim</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">mnist</span>=<span class="cm-variable">input_data</span>.<span class="cm-property">read_data_sets</span>(<span class="cm-string">'MNIST_DATA'</span>,<span class="cm-variable">one_hot</span>=<span class="cm-keyword">True</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">x</span>=<span class="cm-variable">tf</span>.<span class="cm-property">placeholder</span>(<span class="cm-string">"float"</span>,<span class="cm-variable">shape</span>=[<span class="cm-keyword">None</span>,<span class="cm-number">784</span>])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">y_</span>=<span class="cm-variable">tf</span>.<span class="cm-property">placeholder</span>(<span class="cm-string">"float"</span>,<span class="cm-variable">shape</span>=[<span class="cm-keyword">None</span>,<span class="cm-number">10</span>])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment">#cast x to 3D</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">x_image</span>=<span class="cm-variable">tf</span>.<span class="cm-property">reshape</span>(<span class="cm-variable">x</span>,[<span class="cm-operator">-</span><span class="cm-number">1</span>,<span class="cm-number">28</span>,<span class="cm-number">28</span>,<span class="cm-number">1</span>])<span class="cm-comment">#shape of x is [N,28,28,1]</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="">​</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment">#conv layer1</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">net</span>=<span class="cm-variable">slim</span>.<span class="cm-property">conv2d</span>(<span class="cm-variable">x_image</span>,<span class="cm-number">32</span>,[<span class="cm-number">3</span>,<span class="cm-number">3</span>],<span class="cm-variable">scope</span>=<span class="cm-string">'conv1'</span>)<span class="cm-comment">#shape of net is [N,28,28,32]</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment">#conv layer2</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">net</span>=<span class="cm-variable">slim</span>.<span class="cm-property">conv2d</span>(<span class="cm-variable">net</span>,<span class="cm-number">64</span>,[<span class="cm-number">3</span>,<span class="cm-number">3</span>],<span class="cm-variable">scope</span>=<span class="cm-string">'conv2'</span>)<span class="cm-comment">#shape of net is [N,28,28,64]</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">net</span>=<span class="cm-variable">slim</span>.<span class="cm-property">max_pool2d</span>(<span class="cm-variable">net</span>,[<span class="cm-number">2</span>,<span class="cm-number">2</span>],<span class="cm-variable">scope</span>=<span class="cm-string">'pool2'</span>)<span class="cm-comment">#shape of net is [N,14,14,64]</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment">#reshape for full connection</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">net</span>=<span class="cm-variable">tf</span>.<span class="cm-property">reshape</span>(<span class="cm-variable">net</span>,[<span class="cm-operator">-</span><span class="cm-number">1</span>,<span class="cm-number">14</span><span class="cm-operator">*</span><span class="cm-number">14</span><span class="cm-operator">*</span><span class="cm-number">64</span>])<span class="cm-comment">#[N,14*14*64]</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment">#fc1</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">net</span>=<span class="cm-variable">slim</span>.<span class="cm-property">fully_connected</span>(<span class="cm-variable">net</span>,<span class="cm-number">1024</span>,<span class="cm-variable">scope</span>=<span class="cm-string">'fc1'</span>)<span class="cm-comment">#shape of net is [N,1024]</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment">#dropout layer</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">keep_prob</span>=<span class="cm-variable">tf</span>.<span class="cm-property">placeholder</span>(<span class="cm-string">'float'</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">net</span>=<span class="cm-variable">tf</span>.<span class="cm-property">nn</span>.<span class="cm-property">dropout</span>(<span class="cm-variable">net</span>,<span class="cm-variable">keep_prob</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment">#fc2</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">net</span>=<span class="cm-variable">slim</span>.<span class="cm-property">fully_connected</span>(<span class="cm-variable">net</span>,<span class="cm-number">10</span>,<span class="cm-variable">scope</span>=<span class="cm-string">'fc2'</span>)<span class="cm-comment">#[N,10]</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment">#softmax</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">y</span>=<span class="cm-variable">tf</span>.<span class="cm-property">nn</span>.<span class="cm-property">softmax</span>(<span class="cm-variable">net</span>)<span class="cm-comment">#[N,10]</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">cross_entropy</span>=<span class="cm-operator">-</span><span class="cm-variable">tf</span>.<span class="cm-property">reduce_sum</span>(<span class="cm-variable">tf</span>.<span class="cm-property">multiply</span>(<span class="cm-variable">y_</span>,<span class="cm-variable">tf</span>.<span class="cm-property">log</span>(<span class="cm-variable">y</span>)))<span class="cm-comment">#y and _y have same shape.</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">l2_loss</span> = <span class="cm-variable">tf</span>.<span class="cm-property">add_n</span>([<span class="cm-variable">tf</span>.<span class="cm-property">nn</span>.<span class="cm-property">l2_loss</span>(<span class="cm-variable">w</span>) </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-keyword">for</span> <span class="cm-variable">w</span> <span class="cm-keyword">in</span> <span class="cm-variable">tf</span>.<span class="cm-property">get_collection</span>(<span class="cm-variable">tf</span>.<span class="cm-property">GraphKeys</span>.<span class="cm-property">TRAINABLE_VARIABLES</span>)])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">total_loss</span> = <span class="cm-variable">cross_entropy</span> <span class="cm-operator">+</span> <span class="cm-number">7e-5</span><span class="cm-operator">*</span><span class="cm-variable">l2_loss</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="">​</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">train_step</span>=<span class="cm-variable">tf</span>.<span class="cm-property">train</span>.<span class="cm-property">AdamOptimizer</span>(<span class="cm-number">1e-4</span>).<span class="cm-property">minimize</span>(<span class="cm-variable">cross_entropy</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="">​</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment"># 验证训练的模型</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">correct_prediction</span> = <span class="cm-variable">tf</span>.<span class="cm-property">equal</span>(<span class="cm-variable">tf</span>.<span class="cm-property">argmax</span>(<span class="cm-variable">out</span>, <span class="cm-number">1</span>), <span class="cm-variable">tf</span>.<span class="cm-property">argmax</span>(<span class="cm-variable">y</span>, <span class="cm-number">1</span>))</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">accuracy</span> = <span class="cm-variable">tf</span>.<span class="cm-property">reduce_mean</span>(<span class="cm-variable">tf</span>.<span class="cm-property">cast</span>(<span class="cm-variable">correct_prediction</span>, <span class="cm-variable">tf</span>.<span class="cm-property">float32</span>))</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="">​</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">init</span>=<span class="cm-variable">tf</span>.<span class="cm-property">global_variables_initializer</span>()</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">with</span> <span class="cm-variable">tf</span>.<span class="cm-property">Session</span>() <span class="cm-keyword">as</span> <span class="cm-variable">sess</span>:</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">sess</span>.<span class="cm-property">run</span>(<span class="cm-variable">init</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-keyword">for</span> <span class="cm-variable">i</span> <span class="cm-keyword">in</span> <span class="cm-builtin">range</span>(<span class="cm-number">3000</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">batch_x</span>, <span class="cm-variable">batch_y</span>=<span class="cm-variable">mnist</span>.<span class="cm-property">train</span>.<span class="cm-property">next_batch</span>(<span class="cm-number">128</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">_</span>, <span class="cm-variable">loss</span>, <span class="cm-variable">l2_loss_value</span>, <span class="cm-variable">total_loss_value</span> = <span class="cm-variable">sess</span>.<span class="cm-property">run</span>(</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  [<span class="cm-variable">train_step</span>, <span class="cm-variable">cross_entropy</span>, <span class="cm-variable">l2_loss</span>, <span class="cm-variable">total_loss</span>],</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">feed_dict</span>={<span class="cm-variable">x</span>: <span class="cm-variable">batch_x</span>, <span class="cm-variable">y</span>: <span class="cm-variable">batch_y</span>, <span class="cm-variable">keep_prob</span>: <span class="cm-number">0.5</span>})</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-keyword">if</span> <span class="cm-variable">i</span><span class="cm-operator">%</span><span class="cm-number">100</span>==<span class="cm-number">0</span>:</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-builtin">print</span>(<span class="cm-string">"step %d, entropy loss: %f, l2_loss: %f, total loss: %f"</span> <span class="cm-operator">%</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  (<span class="cm-variable">step</span><span class="cm-operator">+</span><span class="cm-number">1</span>, <span class="cm-variable">loss</span>, <span class="cm-variable">l2_loss_value</span>, <span class="cm-variable">total_loss_value</span>))</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-builtin">print</span>(<span class="cm-string">"Train accuracy:"</span>, <span class="cm-variable">sess</span>.<span class="cm-property">run</span>(<span class="cm-variable">accuracy</span>, <span class="cm-variable">feed_dict</span>={<span class="cm-variable">x</span>: <span class="cm-variable">batch_x</span>, </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <span class="cm-variable">y</span>: <span class="cm-variable">batch_y</span>, <span class="cm-variable">keep_prob</span>:<span class="cm-number">1.0</span>}))</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-null cm-error"> &nbsp; &nbsp;</span><span class="cm-variable">total_accuracy</span>=<span class="cm-variable">sess</span>.<span class="cm-property">run</span>(<span class="cm-variable">accuracy</span>,<span class="cm-variable">feed_dict</span>={<span class="cm-variable">x</span>:<span class="cm-variable">mnist</span>.<span class="cm-property">test</span>.<span class="cm-property">images</span>,</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">y_</span>:<span class="cm-variable">mnist</span>.<span class="cm-property">test</span>.<span class="cm-property">labels</span>,<span class="cm-variable">keep_prob</span>:<span class="cm-number">1.0</span>})</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-builtin">print</span>(<span class="cm-string">"Text accuracy:"</span>, <span class="cm-variable">total_accuracy</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="">​</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 1904px;"></div><div class="CodeMirror-gutters" style="display: none; height: 1904px;"></div></div></div></pre><h3><a name="31-mobilenet-v1" class="md-header-anchor"></a><span>3.1 mobilenet V1</span></h3><p><a href='https://blog.csdn.net/zj360202/article/details/78623567' target='_blank' class='url'>https://blog.csdn.net/zj360202/article/details/78623567</a></p><h3><a name="32-用numpy实现分类器" class="md-header-anchor"></a><span>3.2 用numpy实现分类器</span></h3><p><a href='https://github.com/zlpure/CS231n' target='_blank' class='url'>https://github.com/zlpure/CS231n</a></p><p><strong><span>CNN:</span></strong></p><p><a href='https://github.com/zlpure/CS231n/blob/master/assignment2/cs231n/classifiers/cnn.py' target='_blank' class='url'>https://github.com/zlpure/CS231n/blob/master/assignment2/cs231n/classifiers/cnn.py</a></p><h3><a name="33-tfnamescope和tfvariablescope" class="md-header-anchor"></a><span>3.3 tf.name_scope()和tf.variable_scope()</span></h3><p><span>这两种作用域，对于使用</span><code>tf.Variable()</code><span>方式创建的变量，具有相同的效果，</span><strong><span>都会在变量名称前面，加上域名称</span></strong><span>。对于通过</span><code>tf.get_variable()</code><span>方式创建的变量，只有variable_scope名称会加到变量名称前面，而name_scope不会作为前缀。</span></p><p><strong><span>命名域</span></strong></p><p><code>tf.name_scope()</code><span>主要是方便参数变量的“ 分组 ”和 “ 管理 ”，主要是结合</span><code>tf.Variable()</code><span>一起使用</span></p><pre spellcheck="false" class="md-fences md-end-block ty-contain-cm modeLoaded" lang="python"><div class="CodeMirror cm-s-inner CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">tf</span>.<span class="cm-property">name_scope</span>(<span class="cm-variable">name</span>,<span class="cm-variable">default_name</span>=<span class="cm-keyword">None</span>,<span class="cm-variable">values</span>=<span class="cm-keyword">None</span>)</span></pre></div></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 23px;"></div><div class="CodeMirror-gutters" style="display: none; height: 23px;"></div></div></div></pre><p><span>values这个参数的规定了应该把在</span><code>with tf.name_scope</code><span>区域里生成的tensor放到哪个计算图（graph）里</span></p><p><span>比如：</span></p><pre spellcheck="false" class="md-fences md-end-block ty-contain-cm modeLoaded" lang="python" style="break-inside: unset;"><div class="CodeMirror cm-s-inner CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation" style=""><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">graph_tensor</span> = <span class="cm-variable">tf</span>.<span class="cm-property">Graph</span>()</span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">with</span> <span class="cm-variable">graph_tensor</span>.<span class="cm-property">as_default</span>():</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">A</span> = <span class="cm-variable">tf</span>.<span class="cm-property">constant</span>(<span class="cm-number">1</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable cm-error">graph_1</span> = <span class="cm-variable">tf</span>.<span class="cm-property">Graph</span>()</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">graph_1</span>.<span class="cm-property">as_default</span>()</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">with</span> <span class="cm-variable">tf</span>.<span class="cm-property">name_scope</span>(<span class="cm-keyword">None</span>, <span class="cm-string">"namescope_1"</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">op1</span> = <span class="cm-variable">tf</span>.<span class="cm-property">constant</span>(<span class="cm-number">0</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable cm-error">graph_2</span> = <span class="cm-variable">tf</span>.<span class="cm-property">Graph</span>()</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">graph_2</span>.<span class="cm-property">as_default</span>()</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">with</span> <span class="cm-variable">tf</span>.<span class="cm-property">name_scope</span>(<span class="cm-keyword">None</span>, <span class="cm-string">"namescope_2"</span>,[<span class="cm-variable">A</span>]):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">op2</span> = <span class="cm-variable">tf</span>.<span class="cm-property">constant</span>(<span class="cm-number">0</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-builtin cm-error">print</span>(<span class="cm-variable">op1</span>.<span class="cm-property">graph</span> == <span class="cm-variable">graph_tensor</span>) <span class="cm-comment"># 输出 false</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 340px;"></div><div class="CodeMirror-gutters" style="display: none; height: 340px;"></div></div></div></pre><p><span>小结：name_scope不会作为</span><code>tf.get_variable</code><span>变量的前缀，但是会作为</span><code>tf.Variable</code><span>的前缀。</span></p><p><strong><span>变量域</span></strong></p><p><code>tf.variable_scope()</code><span>一方面也是可以实现变量的“ 分组 ”和“ 管理 ”，主要是结合</span><code>tf.get_variable()</code><span>一起使用</span></p><pre spellcheck="false" class="md-fences md-end-block ty-contain-cm modeLoaded" lang="python"><div class="CodeMirror cm-s-inner CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">tf</span>.<span class="cm-property">variable_scope</span>(<span class="cm-variable">name</span>,<span class="cm-variable">default_name</span>=<span class="cm-keyword">None</span>,<span class="cm-variable">values</span>=<span class="cm-keyword">None</span>,<span class="cm-variable">initializer</span>=<span class="cm-keyword">None</span>,<span class="cm-variable">regularizer</span>=<span class="cm-keyword">None</span>,<span class="cm-variable">caching_device</span>=<span class="cm-keyword">None</span>,<span class="cm-variable">partitioner</span>=<span class="cm-keyword">None</span>,<span class="cm-variable">custom_getter</span>=<span class="cm-keyword">None</span>,<span class="cm-variable">reuse</span>=<span class="cm-keyword">None</span>,<span class="cm-variable">dtype</span>=<span class="cm-keyword">None</span>)</span></pre></div></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 91px;"></div><div class="CodeMirror-gutters" style="display: none; height: 91px;"></div></div></div></pre><p><span>例子：</span></p><pre spellcheck="false" class="md-fences md-end-block ty-contain-cm modeLoaded" lang="python"><div class="CodeMirror cm-s-inner CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation" style=""><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">with</span> <span class="cm-variable">tf</span>.<span class="cm-property">variable_scope</span>(<span class="cm-string">"my_variable_scope"</span>):</span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">v1</span> = <span class="cm-variable">tf</span>.<span class="cm-property">get_variable</span>(<span class="cm-string">"var1"</span>, [<span class="cm-number">1</span>], <span class="cm-variable">dtype</span>=<span class="cm-variable">tf</span>.<span class="cm-property">float32</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">v2</span> = <span class="cm-variable">tf</span>.<span class="cm-property">Variable</span>(<span class="cm-number">1</span>, <span class="cm-variable">name</span>=<span class="cm-string">"var2"</span>, <span class="cm-variable">dtype</span>=<span class="cm-variable">tf</span>.<span class="cm-property">float32</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> </span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable cm-error">a</span> = <span class="cm-variable">tf</span>.<span class="cm-property">add</span>(<span class="cm-variable">v1</span>, <span class="cm-variable">v2</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-variable">v1</span>.<span class="cm-property">name</span>) <span class="cm-comment"># my_variable_scope/var1:0</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-variable">v2</span>.<span class="cm-property">name</span>) <span class="cm-comment"># my_variable_scope/var2:0</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-variable">a</span>.<span class="cm-property">name</span>) <span class="cm-comment"># my_variable_scope/Add:0</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 227px;"></div><div class="CodeMirror-gutters" style="display: none; height: 227px;"></div></div></div></pre><p><a href='#目录'><span>回到顶部</span></a></p><h3><a name="34-tfvariable和tfgetvariable" class="md-header-anchor"></a><span>3.4 tf.Variable()和tf.get_variable()</span></h3><p><span>tf.Variable()             #创建一个全新的变量</span></p><p><span>tf.get_variable()      #创建共享变量</span></p><p><span>使用t</span><code>f.get_variable()</code><span>可以创建两个名字完全一样的变量，这两个变量共享参数</span></p><p><a href='https://www.jianshu.com/p/2061b221cd8f?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendation' target='_blank' class='url'>https://www.jianshu.com/p/2061b221cd8f?utm_campaign=maleskine&utm_content=note&utm_medium=seo_notes&utm_source=recommendation</a></p><p><a href='#目录'><span>回到顶部</span></a></p><h2><a name="4-基础问答" class="md-header-anchor"></a><span>4. 基础问答</span></h2><h3><a name="41-分类和回归有什么区别" class="md-header-anchor"></a><span>4.1 分类和回归有什么区别？</span></h3><p><span>分类模型和回归模型本质一样，分类模型是将回归模型的输出离散化。</span></p><p><span>分类问题是指，给定一个新的模式，根据训练集推断它所对应的类别（如：+1，-1），是一种定性输出，也叫离散变量预测； </span>
<span>回归问题是指，给定一个新的模式，根据训练集推断它所对应的输出值（实数）是多少，是一种定量输出，也叫连续变量预测。</span></p><p><a href='https://blog.csdn.net/laobai1015/article/details/83059178' target='_blank' class='url'>https://blog.csdn.net/laobai1015/article/details/83059178</a></p><h3><a name="42-简述svm" class="md-header-anchor"></a><span>4.2 简述SVM</span></h3><p><span>有哪些核函数</span></p><p><span>二类分类模型，其基本模型定义为特征空间上的间隔最大的线性分类器，其学习策略便是间隔最大化</span></p><p><a href='#目录'><span>回到顶部</span></a></p><h3><a name="43-简述k-means" class="md-header-anchor"></a><span>4.3 简述K-Means</span></h3><p><span>算法思想：</span></p><blockquote><p><span>选择K个点作为初始质心</span><br/><span>repeat</span><br/><span> 将每个点指派到最近的质心，形成K个簇</span><br/><span> 重新计算每个簇的质心</span><br/><span>until 簇不发生变化或达到最大迭代次数</span></p></blockquote><p><span>python实现：</span></p><p>&nbsp;</p><p><a href='https://www.cnblogs.com/DOLFAMINGO/p/9360120.html' target='_blank' class='url'>https://www.cnblogs.com/DOLFAMINGO/p/9360120.html</a></p><h3><a name="44-resnet" class="md-header-anchor"></a><span>4.4 ResNet</span></h3><p>&nbsp;</p><h3><a name="45-mobilenet-v1-v2-v3" class="md-header-anchor"></a><span>4.5 mobilenet V1 V2 V3</span></h3><p><span>深度可分离卷积的坏处：</span></p><p><span>对于较小的模型而言，用深度可分离卷积代替传统卷积，模型能力会显著降低</span></p><h3><a name="46-交叉验证" class="md-header-anchor"></a><span>4.6 交叉验证</span></h3><p><strong><span>作用：</span></strong></p><p><span>为了得到更为稳健可靠的模型，对模型的泛化误差进行评估，得到模型泛化误差的近似值。当有多个模型可以选择时，我们通常选择“泛化误差”最小的模型。 </span></p><p><span>交叉验证的方法有许多种，但是最常用的是：留一交叉验证、k折交叉验证</span></p><p><strong><span>k折交叉验证:</span></strong></p><ol start='' ><li><span>将含有N个样本的数据集，分成K份，每份含有N/K个样本。选择其中1份作为测试集，另外K-1份作为训练集，测试集就有K种情况。 </span></li><li><span>在每种情况中，用训练集训练模型，用测试集测试模型，计算模型的泛化误差。</span></li><li><span>交叉验证重复K次，每份验证一次，平均K次的结果或者使用其它结合方式，最终得到一个单一估测，得到模型最终的泛化误差。 </span></li><li><span>将K种情况下，模型的泛化误差取均值，得到模型最终的泛化误差。</span>
<strong><span>注</span></strong><span>：</span></li><li><span>一般2&lt;=K&lt;=10。 k折交叉验证的优势在于，同时重复运用随机产生的子样本进行训练和验证，每次的结果验证一次，10折交叉验证是最常用的。</span></li><li><span>训练集中样本数量要足够多，一般至少大于总样本数的50%。 </span></li><li><span>训练集和测试集必须从完整的数据集中均匀取样。均匀取样的目的是希望减少训练集、测试集与原数据集之间的偏差。当样本数量足够多时，通过随机取样，便可以实现均匀取样的效果。</span></li></ol><p><a href='#目录'><span>回到顶部</span></a></p><h1><a name="计算机视觉" class="md-header-anchor"></a><span>计算机视觉</span></h1><h2><a name="1-目标检测" class="md-header-anchor"></a><span>1. 目标检测</span></h2><h3><a name="11-相关研究" class="md-header-anchor"></a><span>1.1 相关研究</span></h3><p><span>RCNN </span></p><p><span>Fast-RCNN ROI Pooling</span></p><p><span>Faster-RCNN RPN</span></p><p><strong><span>YOLO</span></strong><span> </span></p><p><span>YOLO将一幅图分成SxS个网格，最后输出resize成7x7x30 预测五个值：[x,y,w,h,c] 输出的通道数30=Bx5+CLS，B代表回归的尺度数，CLS为类别数</span></p><p><span>V1 V2 V3损失函数</span></p><p><span>conernet </span></p><p><span>centernet </span></p><h3><a name="11-目标检测中评价指标" class="md-header-anchor"></a><span>1.1 目标检测中评价指标</span></h3><p><strong><span>ROC曲线  AUC值</span></strong><span>：兼顾正负例，正负样本的比例变化时，ROC保持不变</span></p><p><a href='https://blog.csdn.net/u013385925/article/details/80385873' target='_blank' class='url'>https://blog.csdn.net/u013385925/article/details/80385873</a></p><p><span>roc曲线：接收者操作特征(receiveroperating characteristic),roc曲线上每个点反映着对同一信号刺激的感受性。</span></p><p><span>横轴：负正类率，特异度，所有负样本中错误预测为正样本的概率；</span><strong><span>FPR = FP / [ FP + TN]</span></strong><span> </span></p><p><span>纵轴：真正类率，灵敏度，Sensitivity(正类覆盖率) 所有正样本中预测正确的概率；</span><strong><span>TPR = TP / [ TP + FN]</span></strong></p><p><span>得到AUC的两种办法</span></p><ol start='' ><li><span>随机取正负样本，正样本的预测分数大于负样本的分数的概率</span></li><li><span>ROC曲线下面积</span></li></ol><p><strong><span>PR曲线  mAP</span></strong><span>：主要关心正例 </span></p><p><span>VOC07和VOC10不一样   VOC07是有多少个precision有多少点，VOC10是有多少个recall就有多少点</span></p><p><span>这个好！</span><a href='https://blog.csdn.net/aaon22357/article/details/87723972' target='_blank' class='url'>https://blog.csdn.net/aaon22357/article/details/87723972</a></p><p><a href='https://blog.csdn.net/hsqyc/article/details/81702437' target='_blank' class='url'>https://blog.csdn.net/hsqyc/article/details/81702437</a></p><p><span>非常详细：</span><a href='https://blog.csdn.net/Elva_23/article/details/83310350' target='_blank' class='url'>https://blog.csdn.net/Elva_23/article/details/83310350</a></p><p><span>AP是指average precision，平均精确率，即多类预测的时候每一类的precision取平均，mAP就是平均每类的精度均值。</span></p><p><span>P: 一张图片里，类别C预测正确的框框/图像中类别C的框框总数</span></p><p><span>AP: 一个数据集里，所有关于类别C的精度总和/含有类别C的图像数</span></p><p><span>mAP: 一个数据集里，所有类别的AP/类别总数</span></p><p><span>AR@1 AR@10  在每个图像中检测到</span><strong><span>固定数量</span></strong><span>的最大召回（recall）</span></p><p><img src="./image/1/2-1.1.png" referrerpolicy="no-referrer" alt="2018063022222"></p><h3><a name="12-focal-loss" class="md-header-anchor"></a><span>1.2 focal loss</span></h3><p><span>focal loss：</span></p><p><img src="/image/2-1-2.png" referrerpolicy="no-referrer" alt="1559877160483"></p><p><span>在Focal Loss中，它更关心难分类样本，不太关心易分类样本</span></p><p><span>平衡因子alpha，用来平衡正负样本本身的比例不均。alpha取值范围0~1，当alpha&gt;0.5时，可以相对增加y=1所占的比例。实现正负样本的平衡。</span></p><p><span>gamma&gt;0，gamma调节简单样本权重降低的速率，何凯明的试验中，gamma为2是最优的</span></p><h3><a name="13-smooth-l2" class="md-header-anchor"></a><span>1.3 smooth L2</span></h3><p>&nbsp;</p><h3><a name="14-边界框回归ground-truth计算" class="md-header-anchor"></a><span>1.4 边界框回归ground truth计算</span></h3><p>&nbsp;</p><h3><a name="15-roipooling--roiwarp-roialign-preciseroi" class="md-header-anchor"></a><span>1.5 ROIPooling  RoIWarp RoIAlign PreciseRoI</span></h3><p><a href='https://blog.csdn.net/m_buddy/article/details/85110124' target='_blank' class='url'>https://blog.csdn.net/m_buddy/article/details/85110124</a></p><h3><a name="16-得到auc的两种办法" class="md-header-anchor"></a><span>1.6 得到AUC的两种办法</span></h3><p><span>随机取正负样本，正样本的预测分数大于负样本的分数的概率</span></p><h3><a name="16-nms原理" class="md-header-anchor"></a><span>1.6 NMS原理</span></h3><p><span>它的作用是去掉检测过程中重复的框，需要</span><strong><span>注意</span></strong><span>的是，NMS一次处理一个类别，如果有N个类别，Non-Maximum Suppression就需要执行N次</span></p><p><span>每个框都对应一个置信度，得分越高说明越接近期望值</span></p><ol start='' ><li><span>选置信最大所对应的box，剩下的box与此计算iou</span></li><li><span>将大于阈值的iou所对应的box剔除</span></li><li><span>得到剩下的box的置信度，再重复1，2步，直到候选box为空</span></li></ol><p><span>代码：</span></p><pre spellcheck="false" class="md-fences md-end-block ty-contain-cm modeLoaded" lang="python" style="break-inside: unset;"><div class="CodeMirror cm-s-inner CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation" style=""><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">numpy</span> <span class="cm-keyword">as</span> <span class="cm-variable">np</span></span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="">​</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">py_cpu_nms</span>(<span class="cm-variable">dets</span>, <span class="cm-variable">thresh</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-string">"""Pure Python NMS baseline."""</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">x1</span> = <span class="cm-variable">dets</span>[:, <span class="cm-number">0</span>]</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">y1</span> = <span class="cm-variable">dets</span>[:, <span class="cm-number">1</span>]</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">x2</span> = <span class="cm-variable">dets</span>[:, <span class="cm-number">2</span>]</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">y2</span> = <span class="cm-variable">dets</span>[:, <span class="cm-number">3</span>]</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">scores</span> = <span class="cm-variable">dets</span>[:, <span class="cm-number">4</span>]</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="">​</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">areas</span> = (<span class="cm-variable">x2</span> <span class="cm-operator">-</span> <span class="cm-variable">x1</span> <span class="cm-operator">+</span> <span class="cm-number">1</span>) <span class="cm-operator">*</span> (<span class="cm-variable">y2</span> <span class="cm-operator">-</span> <span class="cm-variable">y1</span> <span class="cm-operator">+</span> <span class="cm-number">1</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">order</span> = <span class="cm-variable">scores</span>.<span class="cm-property">argsort</span>()[::<span class="cm-operator">-</span><span class="cm-number">1</span>] &nbsp;<span class="cm-comment"># score从大到小的索引值</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-comment"># order = np.argsort(-scores)  # 也可以</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="">​</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">keep</span> = []</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-keyword">while</span> <span class="cm-variable">order</span>.<span class="cm-property">size</span> <span class="cm-operator">&gt;</span> <span class="cm-number">0</span>:</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">i</span> = <span class="cm-variable">order</span>[<span class="cm-number">0</span>] &nbsp;<span class="cm-comment"># 得到第一个最大的索引值</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">keep</span>.<span class="cm-property">append</span>(<span class="cm-variable">i</span>) &nbsp;<span class="cm-comment"># 保留得分最大的索引值</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-comment"># 得到中间inter矩形的坐标</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">xx1</span> = <span class="cm-variable">np</span>.<span class="cm-property">maximum</span>(<span class="cm-variable">x1</span>[<span class="cm-variable">i</span>], <span class="cm-variable">x1</span>[<span class="cm-variable">order</span>[<span class="cm-number">1</span>:]]) &nbsp;<span class="cm-comment"># x1[i]和除了最大的值之外的值作比较</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">yy1</span> = <span class="cm-variable">np</span>.<span class="cm-property">maximum</span>(<span class="cm-variable">y1</span>[<span class="cm-variable">i</span>], <span class="cm-variable">y1</span>[<span class="cm-variable">order</span>[<span class="cm-number">1</span>:]])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">xx2</span> = <span class="cm-variable">np</span>.<span class="cm-property">minimum</span>(<span class="cm-variable">x2</span>[<span class="cm-variable">i</span>], <span class="cm-variable">x2</span>[<span class="cm-variable">order</span>[<span class="cm-number">1</span>:]])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">yy2</span> = <span class="cm-variable">np</span>.<span class="cm-property">minimum</span>(<span class="cm-variable">y2</span>[<span class="cm-variable">i</span>], <span class="cm-variable">y2</span>[<span class="cm-variable">order</span>[<span class="cm-number">1</span>:]])</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="">​</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">w</span> = <span class="cm-variable">np</span>.<span class="cm-property">maximum</span>(<span class="cm-number">0.0</span>, <span class="cm-variable">xx2</span> <span class="cm-operator">-</span> <span class="cm-variable">xx1</span> <span class="cm-operator">+</span> <span class="cm-number">1</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">h</span> = <span class="cm-variable">np</span>.<span class="cm-property">maximum</span>(<span class="cm-number">0.0</span>, <span class="cm-variable">yy2</span> <span class="cm-operator">-</span> <span class="cm-variable">yy1</span> <span class="cm-operator">+</span> <span class="cm-number">1</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">inter</span> = <span class="cm-variable">w</span> <span class="cm-operator">*</span> <span class="cm-variable">h</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">ovr</span> = <span class="cm-variable">inter</span> <span class="cm-operator">/</span> (<span class="cm-variable">areas</span>[<span class="cm-variable">i</span>] <span class="cm-operator">+</span> <span class="cm-variable">areas</span>[<span class="cm-variable">order</span>[<span class="cm-number">1</span>:]] <span class="cm-operator">-</span> <span class="cm-variable">inter</span>) &nbsp;<span class="cm-comment"># 第i个box和其它box的iou</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" class="cm-tab-wrap-hack" style="padding-right: 0.1px;"><span class="cm-tab" role="presentation" cm-text="	">    </span><span class="cm-tab" role="presentation" cm-text="	">    </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-comment"># 大于阈值的就不管了（去除掉），小于阈值的就可能是另一个目标框，留下来继续比较</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">inds</span> = <span class="cm-variable">np</span>.<span class="cm-property">where</span>(<span class="cm-variable">ovr</span> <span class="cm-operator">&lt;</span>= <span class="cm-variable">thresh</span>)[<span class="cm-number">0</span>] &nbsp;<span class="cm-comment"># 返回满足条件的order[1:]中的索引值</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp; &nbsp; &nbsp;<span class="cm-variable">order</span> = <span class="cm-variable">order</span>[<span class="cm-variable">inds</span> <span class="cm-operator">+</span> <span class="cm-number">1</span>] &nbsp;<span class="cm-comment"># +1得到order中的索引值 </span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="">​</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-keyword">return</span> <span class="cm-variable">keep</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 907px;"></div><div class="CodeMirror-gutters" style="display: none; height: 907px;"></div></div></div></pre><p><strong><span>soft NMS</span></strong></p><p><span>对于稠密物体检测，当同类的两个目标距离较近时，如果使用原生的nms，就会导致其中一个目标不能被召回，为了提高这种情况下目标检测的召回率，Soft-NMS应运而生</span></p><p><span>加入了高斯惩罚，IOU越大的框，得分越低</span></p><p><strong><span>softer NMS</span></strong></p><p><span>加入第三分支，得出回归出四个位置的标准差，标准差越小，置信越高</span></p><p><a href='https://blog.csdn.net/diligent_321/article/details/85859462' target='_blank' class='url'>https://blog.csdn.net/diligent_321/article/details/85859462</a></p><p><span>softer-NMS关注的是单个框的定位精度，而NMS和soft-NMS关注的是单个框的冗余性，显然关注点不同，所以softer-NMS可以和soft-NMS组合使用，此时效果更佳</span></p><p><a href='#目录'><span>回到顶部</span></a></p><h2><a name="2-语义分割" class="md-header-anchor"></a><span>2. 语义分割</span></h2><h3><a name="21-相关研究" class="md-header-anchor"></a><span>2.1 相关研究</span></h3><p><span>FCN</span></p><p><span>UNet</span></p><p><span>DeepLab 类别多</span></p><h3><a name="22-评价指标" class="md-header-anchor"></a><span>2.2 评价指标</span></h3><p><span>PA(Pixel Accuracy)，mPA，平均像素精度。预测正确的像素占总像素的比例</span></p><p><span>IOU， mIOU，平均IOU</span></p><p><a href='#目录'><span>回到顶部</span></a></p><h3><a name="23-dice-loss" class="md-header-anchor"></a><span>2.3 DICE loss</span></h3><p><strong><span>Dice系数</span></strong><span>, 根据 Lee Raymond Dice命名，是一种集合相似度度量函数，通常用于计算两个样本的相似度(值范围为 [0, 1])：</span></p><div contenteditable="false" spellcheck="false" class="mathjax-block md-end-block md-math-block md-rawblock" id="mathjax-n480" cid="n480" mdtype="math_block"><div class="md-rawblock-container md-math-container" tabindex="-1"><div class="MathJax_SVG_Display" style="text-align: center;"><span class="MathJax_SVG" id="MathJax-Element-5-Frame" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="14.196ex" height="6.079ex" viewBox="0 -1560 6112 2617.5" role="img" focusable="false" style="vertical-align: -2.456ex; max-width: 100%;"><defs><path stroke-width="0" id="E31-MJMATHI-73" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path><path stroke-width="0" id="E31-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path stroke-width="0" id="E31-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path stroke-width="0" id="E31-MJMAIN-7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path><path stroke-width="0" id="E31-MJMATHI-58" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path><path stroke-width="0" id="E31-MJSZ1-22C2" d="M139 -217Q127 -241 114 -246Q106 -249 97 -249Q67 -249 57 -220Q55 -214 55 102Q55 152 55 221T54 312Q54 422 60 464T91 554Q120 612 165 654T257 714T337 741T392 749Q393 750 402 750Q414 750 422 749Q557 749 660 659T776 430Q777 422 777 102Q777 -214 775 -220Q765 -249 735 -249Q716 -249 708 -241T694 -217L692 428L690 441Q674 540 597 603T416 666H409Q388 666 364 662T294 638T212 581Q156 523 142 441L140 428L139 105V-217Z"></path><path stroke-width="0" id="E31-MJMATHI-59" d="M66 637Q54 637 49 637T39 638T32 641T30 647T33 664T42 682Q44 683 56 683Q104 680 165 680Q288 680 306 683H316Q322 677 322 674T320 656Q316 643 310 637H298Q242 637 242 624Q242 619 292 477T343 333L346 336Q350 340 358 349T379 373T411 410T454 461Q546 568 561 587T577 618Q577 634 545 637Q528 637 528 647Q528 649 530 661Q533 676 535 679T549 683Q551 683 578 682T657 680Q684 680 713 681T746 682Q763 682 763 673Q763 669 760 657T755 643Q753 637 734 637Q662 632 617 587Q608 578 477 424L348 273L322 169Q295 62 295 57Q295 46 363 46Q379 46 384 45T390 35Q390 33 388 23Q384 6 382 4T366 1Q361 1 324 1T232 2Q170 2 138 2T102 1Q84 1 84 9Q84 14 87 24Q88 27 89 30T90 35T91 39T93 42T96 44T101 45T107 45T116 46T129 46Q168 47 180 50T198 63Q201 68 227 171L252 274L129 623Q128 624 127 625T125 627T122 629T118 631T113 633T105 634T96 635T83 636T66 637Z"></path><path stroke-width="0" id="E31-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E31-MJMATHI-73" x="0" y="0"></use><use xlink:href="#E31-MJMAIN-3D" x="746" y="0"></use><g transform="translate(1524,0)"><g transform="translate(397,0)"><rect stroke="none" width="4069" height="60" x="0" y="220"></rect><g transform="translate(116,715)"><use xlink:href="#E31-MJMAIN-32" x="0" y="0"></use><use xlink:href="#E31-MJMAIN-7C" x="500" y="0"></use><use xlink:href="#E31-MJMATHI-58" x="778" y="0"></use><use xlink:href="#E31-MJSZ1-22C2" x="1796" y="-1"></use><use xlink:href="#E31-MJMATHI-59" x="2796" y="0"></use><use xlink:href="#E31-MJMAIN-7C" x="3559" y="0"></use></g><g transform="translate(60,-716)"><use xlink:href="#E31-MJMAIN-7C" x="0" y="0"></use><use xlink:href="#E31-MJMATHI-58" x="278" y="0"></use><use xlink:href="#E31-MJMAIN-7C" x="1130" y="0"></use><use xlink:href="#E31-MJMAIN-2B" x="1630" y="0"></use><use xlink:href="#E31-MJMAIN-7C" x="2630" y="0"></use><use xlink:href="#E31-MJMATHI-59" x="2908" y="0"></use><use xlink:href="#E31-MJMAIN-7C" x="3671" y="0"></use></g></g></g></g></svg></span></div><script type="math/tex; mode=display" id="MathJax-Element-5">s = \frac{2 |X \bigcap Y|}{|X| + |Y|}</script></div></div><p><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.27ex" height="2.577ex" viewBox="0 -806.1 1408 1109.7" role="img" focusable="false" style="vertical-align: -0.705ex;"><defs><path stroke-width="0" id="E18-MJMAIN-7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path><path stroke-width="0" id="E18-MJMATHI-58" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E18-MJMAIN-7C" x="0" y="0"></use><use xlink:href="#E18-MJMATHI-58" x="278" y="0"></use><use xlink:href="#E18-MJMAIN-7C" x="1130" y="0"></use></g></svg></span><script type="math/tex">|X|</script><span>和</span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="3.063ex" height="2.577ex" viewBox="0 -806.1 1319 1109.7" role="img" focusable="false" style="vertical-align: -0.705ex;"><defs><path stroke-width="0" id="E19-MJMAIN-7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path><path stroke-width="0" id="E19-MJMATHI-59" d="M66 637Q54 637 49 637T39 638T32 641T30 647T33 664T42 682Q44 683 56 683Q104 680 165 680Q288 680 306 683H316Q322 677 322 674T320 656Q316 643 310 637H298Q242 637 242 624Q242 619 292 477T343 333L346 336Q350 340 358 349T379 373T411 410T454 461Q546 568 561 587T577 618Q577 634 545 637Q528 637 528 647Q528 649 530 661Q533 676 535 679T549 683Q551 683 578 682T657 680Q684 680 713 681T746 682Q763 682 763 673Q763 669 760 657T755 643Q753 637 734 637Q662 632 617 587Q608 578 477 424L348 273L322 169Q295 62 295 57Q295 46 363 46Q379 46 384 45T390 35Q390 33 388 23Q384 6 382 4T366 1Q361 1 324 1T232 2Q170 2 138 2T102 1Q84 1 84 9Q84 14 87 24Q88 27 89 30T90 35T91 39T93 42T96 44T101 45T107 45T116 46T129 46Q168 47 180 50T198 63Q201 68 227 171L252 274L129 623Q128 624 127 625T125 627T122 629T118 631T113 633T105 634T96 635T83 636T66 637Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E19-MJMAIN-7C" x="0" y="0"></use><use xlink:href="#E19-MJMATHI-59" x="278" y="0"></use><use xlink:href="#E19-MJMAIN-7C" x="1041" y="0"></use></g></svg></span><script type="math/tex">|Y|</script><span>分别表示 X 和 Y 的元素个数，可采用直接简单的元素相加；也有采用取元素平方求和的做法。</span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="7.751ex" height="2.577ex" viewBox="0 -806.1 3337.3 1109.7" role="img" focusable="false" style="vertical-align: -0.705ex;"><defs><path stroke-width="0" id="E20-MJMAIN-7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path><path stroke-width="0" id="E20-MJMATHI-58" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path><path stroke-width="0" id="E20-MJSZ1-22C2" d="M139 -217Q127 -241 114 -246Q106 -249 97 -249Q67 -249 57 -220Q55 -214 55 102Q55 152 55 221T54 312Q54 422 60 464T91 554Q120 612 165 654T257 714T337 741T392 749Q393 750 402 750Q414 750 422 749Q557 749 660 659T776 430Q777 422 777 102Q777 -214 775 -220Q765 -249 735 -249Q716 -249 708 -241T694 -217L692 428L690 441Q674 540 597 603T416 666H409Q388 666 364 662T294 638T212 581Q156 523 142 441L140 428L139 105V-217Z"></path><path stroke-width="0" id="E20-MJMATHI-59" d="M66 637Q54 637 49 637T39 638T32 641T30 647T33 664T42 682Q44 683 56 683Q104 680 165 680Q288 680 306 683H316Q322 677 322 674T320 656Q316 643 310 637H298Q242 637 242 624Q242 619 292 477T343 333L346 336Q350 340 358 349T379 373T411 410T454 461Q546 568 561 587T577 618Q577 634 545 637Q528 637 528 647Q528 649 530 661Q533 676 535 679T549 683Q551 683 578 682T657 680Q684 680 713 681T746 682Q763 682 763 673Q763 669 760 657T755 643Q753 637 734 637Q662 632 617 587Q608 578 477 424L348 273L322 169Q295 62 295 57Q295 46 363 46Q379 46 384 45T390 35Q390 33 388 23Q384 6 382 4T366 1Q361 1 324 1T232 2Q170 2 138 2T102 1Q84 1 84 9Q84 14 87 24Q88 27 89 30T90 35T91 39T93 42T96 44T101 45T107 45T116 46T129 46Q168 47 180 50T198 63Q201 68 227 171L252 274L129 623Q128 624 127 625T125 627T122 629T118 631T113 633T105 634T96 635T83 636T66 637Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E20-MJMAIN-7C" x="0" y="0"></use><use xlink:href="#E20-MJMATHI-58" x="278" y="0"></use><use xlink:href="#E20-MJSZ1-22C2" x="1296" y="-1"></use><use xlink:href="#E20-MJMATHI-59" x="2296" y="0"></use><use xlink:href="#E20-MJMAIN-7C" x="3059" y="0"></use></g></svg></span><script type="math/tex">|X \bigcap Y|</script><span>近似为预测图与 GT 分割图之间的点乘</span></p><p><span>其中，分子中的系数 2，是因为分母存在重复计算 X 和 Y 之间的共同元素的原因.</span></p><p><strong><span>dice loss 比较适用于样本极度不均的情况</span></strong><span>，一般的情况下，使用 dice loss 会对反向传播造成不利的影响，容易使训练变得不稳定.</span></p><pre spellcheck="false" class="md-fences md-end-block ty-contain-cm modeLoaded" lang="python"><div class="CodeMirror cm-s-inner CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation" style=""><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">smooth</span> = <span class="cm-number">1.</span> <span class="cm-comment"># 用于防止分母为0.</span></span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">dice_coef</span>(<span class="cm-variable">y_true</span>, <span class="cm-variable">y_pred</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">y_true_f</span> = <span class="cm-variable">K</span>.<span class="cm-property">flatten</span>(<span class="cm-variable">y_true</span>) <span class="cm-comment"># 将 y_true 拉伸为一维.</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">y_pred_f</span> = <span class="cm-variable">K</span>.<span class="cm-property">flatten</span>(<span class="cm-variable">y_pred</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-variable">intersection</span> = <span class="cm-variable">K</span>.<span class="cm-property">sum</span>(<span class="cm-variable">y_true_f</span> <span class="cm-operator">*</span> <span class="cm-variable">y_pred_f</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-keyword">return</span> (<span class="cm-number">2.</span> <span class="cm-operator">*</span> <span class="cm-variable">intersection</span> <span class="cm-operator">+</span> <span class="cm-variable">smooth</span>) <span class="cm-operator">/</span> (<span class="cm-variable">K</span>.<span class="cm-property">sum</span>(<span class="cm-variable">y_true_f</span> <span class="cm-operator">*</span> <span class="cm-variable">y_true_f</span>) <span class="cm-operator">+</span> <span class="cm-variable">K</span>.<span class="cm-property">sum</span>(<span class="cm-variable">y_pred_f</span> <span class="cm-operator">*</span> <span class="cm-variable">y_pred_f</span>) <span class="cm-operator">+</span> <span class="cm-variable">smooth</span>)</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="">​</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">def</span> <span class="cm-def">dice_coef_loss</span>(<span class="cm-variable">y_true</span>, <span class="cm-variable">y_pred</span>):</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"> &nbsp; &nbsp;<span class="cm-keyword">return</span> <span class="cm-number">1.</span> <span class="cm-operator">-</span> <span class="cm-variable">dice_coef</span>(<span class="cm-variable">y_true</span>, <span class="cm-variable">y_pred</span>)</span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 272px;"></div><div class="CodeMirror-gutters" style="display: none; height: 272px;"></div></div></div></pre><p>&nbsp;</p><h2><a name="3-目标跟踪" class="md-header-anchor"></a><span>3. 目标跟踪</span></h2><h3><a name="31-孪生网络" class="md-header-anchor"></a><span>3.1 孪生网络</span></h3><p>&nbsp;</p><h3><a name="32-相关研究" class="md-header-anchor"></a><span>3.2 相关研究</span></h3><p>&nbsp;</p><h1><a name="python" class="md-header-anchor"></a><span>Python</span></h1><h2><a name="1-python深拷贝和浅拷贝区别" class="md-header-anchor"></a><span>1. python深拷贝和浅拷贝区别</span></h2><p><span>※ 可变对象是指，可以修改其所指向的地址中的值。python可变数据类型有：list, dict, set</span></p><p><span>※ 不可变对象是指，所指向的地址上值是不能修改的，</span><strong><span>如果修改了这个对象的值，那么它指向的地址就改变了</span></strong></p><blockquote><p><span>在浅拷贝时，拷贝出来的</span><strong><span>新对象的地址和原对象是不一样的</span></strong><span>，但是</span><strong><span>新对象里面的可变元素（如列表）的地址</span></strong><span>和原对象里的可变元素的地址是相同的，也就是说浅拷贝它拷贝的是浅层次的数据结构（不可变元素），对象里的可变元素作为深层次的数据结构并没有被拷贝到新地址里面去，而是和原对象里的可变元素指向同一个地址，所以在新对象或原对象里对这个可变元素做修改时，两个对象是同时改变的，但是深拷贝不会这样，这个是浅拷贝相对于深拷贝最根本的区别。</span></p></blockquote><p><span>浅拷贝和深拷贝出来的新对象的地址和原对象都是不一样的，区别在于，当元素中有可变数据类型时，浅拷贝的新对象中的可变数据地址和原对象中的是一样的，如果改变原对象中此元素的内容，新对象中的也会变，反之，如果当新对象中可变元素改变了，也同样会影响原对象。</span></p><pre spellcheck="false" class="md-fences md-end-block ty-contain-cm modeLoaded" lang="python"><div class="CodeMirror cm-s-inner CodeMirror-wrap" lang="python"><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation" style=""><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-keyword">import</span> <span class="cm-variable">copy</span></span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">a</span>=[<span class="cm-number">1</span>,<span class="cm-number">2</span>,<span class="cm-number">3</span>,<span class="cm-number">4</span>,<span class="cm-number">5</span>,[<span class="cm-string">'a'</span>,<span class="cm-string">'b'</span>]]</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-comment">#原始对象</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">b</span>=<span class="cm-variable">a</span> &nbsp;<span class="cm-comment"># 赋值，一个地址的两个引用</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">c</span>=<span class="cm-variable">copy</span>.<span class="cm-property">copy</span>(<span class="cm-variable">a</span>) &nbsp;<span class="cm-comment"># 对象拷贝，浅拷贝，改变a中可变元素的值，c中也会跟着改变</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-variable">d</span>=<span class="cm-variable">copy</span>.<span class="cm-property">deepcopy</span>(<span class="cm-variable">a</span>) &nbsp;<span class="cm-comment"># 对象拷贝，深拷贝</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span cm-text="">​</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-string">"a="</span>,<span class="cm-variable">a</span>,<span class="cm-string">" &nbsp;  id(a)="</span>,<span class="cm-builtin">id</span>(<span class="cm-variable">a</span>),<span class="cm-string">"id(a[5])="</span>,<span class="cm-builtin">id</span>(<span class="cm-variable">a</span>[<span class="cm-number">5</span>])) &nbsp;<span class="cm-comment"># 1</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-string">"b="</span>,<span class="cm-variable">b</span>,<span class="cm-string">" &nbsp;  id(b)="</span>,<span class="cm-builtin">id</span>(<span class="cm-variable">b</span>),<span class="cm-string">"id(b[5])="</span>,<span class="cm-builtin">id</span>(<span class="cm-variable">b</span>[<span class="cm-number">5</span>])) &nbsp;<span class="cm-comment"># 2</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-string">"c="</span>,<span class="cm-variable">c</span>,<span class="cm-string">" &nbsp;  id(c)="</span>,<span class="cm-builtin">id</span>(<span class="cm-variable">c</span>),<span class="cm-string">"id(c[5])="</span>,<span class="cm-builtin">id</span>(<span class="cm-variable">c</span>[<span class="cm-number">5</span>])) &nbsp;<span class="cm-comment"># 3</span></span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;"><span class="cm-builtin">print</span>(<span class="cm-string">"d="</span>,<span class="cm-variable">d</span>,<span class="cm-string">" &nbsp;  id(d)="</span>,<span class="cm-builtin">id</span>(<span class="cm-variable">d</span>),<span class="cm-string">"id(d[5])="</span>,<span class="cm-builtin">id</span>(<span class="cm-variable">d</span>[<span class="cm-number">5</span>])) &nbsp;<span class="cm-comment"># 4</span></span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 363px;"></div><div class="CodeMirror-gutters" style="display: none; height: 363px;"></div></div></div></pre><p><span>结果如下：</span></p><pre spellcheck="false" class="md-fences md-end-block ty-contain-cm modeLoaded" lang=""><div class="CodeMirror cm-s-inner CodeMirror-wrap" lang=""><div style="overflow: hidden; position: relative; width: 3px; height: 0px; top: 0px; left: 8px;"><textarea autocorrect="off" autocapitalize="off" spellcheck="false" tabindex="0" style="position: absolute; bottom: -1em; padding: 0px; width: 1000px; height: 1em; outline: none;"></textarea></div><div class="CodeMirror-scrollbar-filler" cm-not-content="true"></div><div class="CodeMirror-gutter-filler" cm-not-content="true"></div><div class="CodeMirror-scroll" tabindex="-1"><div class="CodeMirror-sizer" style="margin-left: 0px; margin-bottom: 0px; border-right-width: 0px; padding-right: 0px; padding-bottom: 0px;"><div style="position: relative; top: 0px;"><div class="CodeMirror-lines" role="presentation"><div role="presentation" style="position: relative; outline: none;"><div class="CodeMirror-measure"><pre><span>xxxxxxxxxx</span></pre></div><div class="CodeMirror-measure"></div><div style="position: relative; z-index: 1;"></div><div class="CodeMirror-code" role="presentation"><div class="CodeMirror-activeline" style="position: relative;"><div class="CodeMirror-activeline-background CodeMirror-linebackground"></div><div class="CodeMirror-gutter-background CodeMirror-activeline-gutter" style="left: 0px; width: 0px;"></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">a= [1, 2, 3, 4, 5, ['a', 'b']] &nbsp; &nbsp; id(a)= 2554026259016 id(a[5])= 2554026259080</span></pre></div><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">b= [1, 2, 3, 4, 5, ['a', 'b']] &nbsp; &nbsp; id(b)= 2554026259016 id(b[5])= 2554026259080</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">c= [1, 2, 3, 4, 5, ['a', 'b']] &nbsp; &nbsp; id(c)= 2554025466056 id(c[5])= 2554026259080</span></pre><pre class=" CodeMirror-line " role="presentation"><span role="presentation" style="padding-right: 0.1px;">d= [1, 2, 3, 4, 5, ['a', 'b']] &nbsp; &nbsp; id(d)= 2554026159432 id(d[5])= 2554025040584</span></pre></div></div></div></div></div><div style="position: absolute; height: 0px; width: 1px; border-bottom: 0px solid transparent; top: 181px;"></div><div class="CodeMirror-gutters" style="display: none; height: 181px;"></div></div></div></pre><p><a href='#目录'><span>回到顶部</span></a></p><h2><a name="2-多态和鸭子类型" class="md-header-anchor"></a><span>2. 多态和鸭子类型</span></h2><p><span> 鸭子类型只关注方法，不关注类型</span></p><h2><a name="3-列表和元组的区别" class="md-header-anchor"></a><span>3. 列表和元组的区别</span></h2><p><a href='https://www.jb51.net/article/164440.htm' target='_blank' class='url'>https://www.jb51.net/article/164440.htm</a></p><p><strong><span>区别：</span></strong></p><ol start='' ><li><span>列表是动态数组，可以随意改变内部元素</span></li><li><span>元组是静态数组，它们不可变，不可删除增加，其内部数据一旦创建便无法改变。</span></li><li><span>元组缓存于Python运行时环境，这意味着我们每次使用元组时无须访问内核去分配内存。</span></li><li><span>同样大小的数据，tuple 占用的内存空间更少</span></li><li><span>元组中不能含有不可哈希的列表</span></li></ol><p><strong><span>相同：</span></strong></p><p><span>元组的访问和列表相同</span></p><p><span>多个元组也可以相加</span></p><h2><a name="4-斐波那契数列" class="md-header-anchor"></a><span>4. 斐波那契数列</span></h2><p><a href='https://www.cnblogs.com/happyfan/p/10869805.html' target='_blank' class='url'>https://www.cnblogs.com/happyfan/p/10869805.html</a></p><h2><a name="5-装饰器" class="md-header-anchor"></a><span>5. 装饰器</span></h2><p>&nbsp;</p><h2><a name="6-生成器-迭代器" class="md-header-anchor"></a><span>6. 生成器 迭代器</span></h2><p>&nbsp;</p><h2><a name="7-lambda匿名函数" class="md-header-anchor"></a><span>7. lambda匿名函数</span></h2><p>&nbsp;</p><p><a href='#目录'><span>回到顶部</span></a></p><h2><a name="8-列表中append和extend方法的区别" class="md-header-anchor"></a><span>8. 列表中append()和extend()方法的区别</span></h2><p><span>append()接受一个参数，这个参数是任意数据类型的对象，append将这个对象添加到末尾</span></p><p><span>extend()接受一个参数，这个参数只能是序列，extend将这个序列中的内容添加到末尾。这个序列可以是列表list、元组tuple、集合set、字典dict，若为字典,则仅会将键(key)作为元素依次添加至原列表的末尾。</span></p><h2><a name="9-python中内置的数据结构有几种" class="md-header-anchor"></a><span>9. python中内置的数据结构有几种？</span></h2><p><span>python可变数据类型有：list, dict, set</span></p><p><span>a. 整型 int、 长整型 long、浮点型 float、 复数 complex</span></p><p><span>b. 字符串 str、 列表 list、 元组 tuple</span></p><p><span>c. 字典 dict 、 集合 set</span></p><p><span>d. Python3 中没有 long，只有无限精度的 int</span></p><h2><a name="10-类中的new和init有啥区别" class="md-header-anchor"></a><span>10. 类中的new和init有啥区别？</span></h2><ol start='' ><li><span>new的功能是在生成对象之前所做的动作，接受的参数是cls 类，必须要接一个返回对象</span></li><li><span>init是在对象生成之后完善对象的属性 它接受的是self 对象</span></li><li><span>对象生成是在 new 里面 return （返回一个对象）</span></li><li><span>故而“ 本质上 ”来说，</span><strong><span>new</span></strong><span>()方法负责创建实例，而</span><strong><span>init</span></strong><span>()仅仅是负责实例属性相关的初始化而已，执行顺序是，先new创建当前类的实例，然后init完善实例的属性</span></li></ol><p><a href='#目录'><span>回到顶部</span></a></p><h1><a name="数据结构" class="md-header-anchor"></a><span>数据结构</span></h1><h2><a name="1-快速排序" class="md-header-anchor"></a><span>1. 快速排序</span></h2><p><a href='https://www.cnblogs.com/happyfan/p/10529582.html' target='_blank' class='url'>https://www.cnblogs.com/happyfan/p/10529582.html</a></p><h2><a name="2-堆排序" class="md-header-anchor"></a><span>2. 堆排序</span></h2><p>&nbsp;</p><h2><a name="3-二叉树" class="md-header-anchor"></a><span>3. 二叉树</span></h2><p><strong><span>二叉树</span></strong></p><p><span>★  高度为k的满二叉树的总节点数是</span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="6.25ex" height="2.577ex" viewBox="0 -956.9 2690.8 1109.7" role="img" focusable="false" style="vertical-align: -0.355ex;"><defs><path stroke-width="0" id="E21-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path stroke-width="0" id="E21-MJMATHI-6B" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path><path stroke-width="0" id="E21-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path stroke-width="0" id="E21-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E21-MJMAIN-32" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E21-MJMATHI-6B" x="707" y="555"></use><use xlink:href="#E21-MJMAIN-2212" x="1190" y="0"></use><use xlink:href="#E21-MJMAIN-31" x="2190" y="0"></use></g></svg></span><script type="math/tex">2^k-1</script></p><p><span>★ 如果</span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.447ex" height="1.76ex" viewBox="0 -504.6 1053.6 757.9" role="img" focusable="false" style="vertical-align: -0.588ex;"><defs><path stroke-width="0" id="E22-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E22-MJMAIN-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E22-MJMATHI-6E" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E22-MJMAIN-30" x="848" y="-213"></use></g></svg></span><script type="math/tex">n_0</script><span>是二叉树的叶节点数，二叉树中度数为2的节点数是</span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.447ex" height="1.644ex" viewBox="0 -504.6 1053.6 707.6" role="img" focusable="false" style="vertical-align: -0.472ex;"><defs><path stroke-width="0" id="E23-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E23-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E23-MJMATHI-6E" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E23-MJMAIN-32" x="848" y="-213"></use></g></svg></span><script type="math/tex">n_2</script><span>，则</span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="11.992ex" height="2.344ex" viewBox="0 -755.9 5163.1 1009.2" role="img" focusable="false" style="vertical-align: -0.588ex;"><defs><path stroke-width="0" id="E24-MJMATHI-6E" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E24-MJMAIN-30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path stroke-width="0" id="E24-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path stroke-width="0" id="E24-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path stroke-width="0" id="E24-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path stroke-width="0" id="E24-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E24-MJMATHI-6E" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E24-MJMAIN-30" x="848" y="-213"></use><use xlink:href="#E24-MJMAIN-3D" x="1331" y="0"></use><g transform="translate(2387,0)"><use xlink:href="#E24-MJMATHI-6E" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E24-MJMAIN-32" x="848" y="-213"></use></g><use xlink:href="#E24-MJMAIN-2B" x="3662" y="0"></use><use xlink:href="#E24-MJMAIN-31" x="4663" y="0"></use></g></svg></span><script type="math/tex">n_0=n_2+1</script></p><p><span>★ 在二叉树中，第</span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="0.801ex" height="1.994ex" viewBox="0 -755.9 345 858.4" role="img" focusable="false" style="vertical-align: -0.238ex;"><defs><path stroke-width="0" id="E25-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E25-MJMATHI-69" x="0" y="0"></use></g></svg></span><script type="math/tex">i</script><span>层的节点数最多是</span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.059ex" height="2.344ex" viewBox="0 -956.9 1747.6 1009.2" role="img" focusable="false" style="vertical-align: -0.121ex;"><defs><path stroke-width="0" id="E26-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path stroke-width="0" id="E26-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path><path stroke-width="0" id="E26-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path><path stroke-width="0" id="E26-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E26-MJMAIN-32" x="0" y="0"></use><g transform="translate(500,392)"><use transform="scale(0.707)" xlink:href="#E26-MJMATHI-69" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E26-MJMAIN-2212" x="345" y="0"></use><use transform="scale(0.707)" xlink:href="#E26-MJMAIN-31" x="1123" y="0"></use></g></g></svg></span><script type="math/tex">2^{i-1}</script></p><p><span>★ 完全二叉树中，假设有N个节点，此二叉树的层数为</span><span class="MathJax_SVG" tabindex="-1" style="font-size: 100%; display: inline-block;"><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="18.347ex" height="2.577ex" viewBox="0 -806.1 7899.6 1109.7" role="img" focusable="false" style="vertical-align: -0.705ex;"><defs><path stroke-width="0" id="E27-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path><path stroke-width="0" id="E27-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path><path stroke-width="0" id="E27-MJMAIN-230A" d="M174 734Q174 735 175 737T177 740T180 744T184 747T189 749T196 750Q206 748 214 735V-210H310H373Q401 -210 411 -213T422 -230T411 -247T369 -251Q362 -251 338 -251T298 -250H190Q178 -246 174 -234V734Z"></path><path stroke-width="0" id="E27-MJMATHI-6C" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path><path stroke-width="0" id="E27-MJMATHI-6F" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path><path stroke-width="0" id="E27-MJMATHI-67" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path><path stroke-width="0" id="E27-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path stroke-width="0" id="E27-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path><path stroke-width="0" id="E27-MJMATHI-4E" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path><path stroke-width="0" id="E27-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path><path stroke-width="0" id="E27-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path><path stroke-width="0" id="E27-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path><path stroke-width="0" id="E27-MJMAIN-230B" d="M229 734Q229 735 230 737T232 740T235 744T239 747T244 749T251 750Q262 748 269 735V-235Q266 -240 256 -249L147 -250H77Q43 -250 32 -247T21 -230T32 -213T72 -209Q79 -209 99 -209T133 -210H229V734Z"></path></defs><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"><use xlink:href="#E27-MJMATHI-68" x="0" y="0"></use><use xlink:href="#E27-MJMAIN-3D" x="853" y="0"></use><g transform="translate(1909,0)"><use xlink:href="#E27-MJMAIN-230A" x="0" y="0"></use><use xlink:href="#E27-MJMATHI-6C" x="444" y="0"></use><use xlink:href="#E27-MJMATHI-6F" x="742" y="0"></use><g transform="translate(1227,0)"><use xlink:href="#E27-MJMATHI-67" x="0" y="0"></use><use transform="scale(0.707)" xlink:href="#E27-MJMAIN-32" x="674" y="-213"></use></g><use xlink:href="#E27-MJMAIN-28" x="2157" y="0"></use><use xlink:href="#E27-MJMATHI-4E" x="2546" y="0"></use><use xlink:href="#E27-MJMAIN-2B" x="3656" y="0"></use><use xlink:href="#E27-MJMAIN-31" x="4656" y="0"></use><use xlink:href="#E27-MJMAIN-29" x="5156" y="0"></use><use xlink:href="#E27-MJMAIN-230B" x="5545" y="-1"></use></g></g></svg></span><script type="math/tex">h=\left \lfloor log_2(N+1) \right \rfloor</script></p><p>&nbsp;</p><p><a href='#目录'><span>回到顶部</span></a></p></div>
</body>
</html>